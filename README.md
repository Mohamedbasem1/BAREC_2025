# ğŸ† BAREC 2025 Shared Task - Championship Results

[![BAREC 2025](https://img.shields.io/badge/BAREC-2025-gold?style=for-the-badge)](https://barec.camel-lab.com/sharedtask2025)
[![First Place](https://img.shields.io/badge/ğŸ¥‡-FIRST_PLACE-FFD700?style=for-the-badge)](https://barec.camel-lab.com/sharedtask2025)
[![Second Place](https://img.shields.io/badge/ğŸ¥ˆ-SECOND_PLACE-C0C0C0?style=for-the-badge)](https://barec.camel-lab.com/sharedtask2025)

## ğŸ¯ Overview

This repository contains our **championship-winning solution** for the **BAREC 2025 Shared Task on Arabic Readability Assessment**. We achieved exceptional performance across multiple tracks, demonstrating the effectiveness of our ensemble-based approach for Arabic text readability assessment.

### ğŸ… Competition Results

| Track | Task | Ranking | Achievement |
|-------|------|---------|-------------|
| **Strict Track** | Sentence-level Readability Assessment | ğŸ¥‡ **1st Place** | [CodaBench](https://barec.camel-lab.com/sharedtask2025) |
| **Strict Track** | Document-level Readability Assessment | ğŸ¥‡ **1st Place** | [CodaBench](https://barec.camel-lab.com/sharedtask2025) |
| **Constrained Track** | Sentence-level Readability Assessment | ğŸ¥‡ **1st Place** | [CodaBench](https://barec.camel-lab.com/sharedtask2025) |
| **Constrained Track** | Document-level Readability Assessment | ğŸ¥‡ **1st Place** | [CodaBench](https://barec.camel-lab.com/sharedtask2025) |
| **Open Track** | Sentence-level Readability Assessment | ğŸ¥‡ **1st Place** | [CodaBench](https://barec.camel-lab.com/sharedtask2025) |
| **Open Track** | Document-level Readability Assessment | ğŸ¥ˆ **2nd Place** | [CodaBench](https://barec.camel-lab.com/sharedtask2025) |

## ğŸš€ Key Achievements

- **5 First Place** positions across different tracks and tasks
- **1 Second Place** in the most competitive Open Track
- Comprehensive solution covering both sentence and document-level readability assessment
- State-of-the-art performance in Arabic text readability evaluation

## ğŸ“Š Track Descriptions

### ğŸ”’ Strict Track
**Constraint:** Models trained exclusively on the BAREC Corpus training set
- **Sentence-level Assessment:** ğŸ¥‡ **Champion**
- **Document-level Assessment:** ğŸ¥‡ **Champion**

### âš–ï¸ Constrained Track  
**Constraint:** BAREC Corpus + SAMER Corpus (document, fragment, word-level) + SAMER Lexicon
- **Sentence-level Assessment:** ğŸ¥‡ **Champion**
- **Document-level Assessment:** ğŸ¥‡ **Champion**

### ğŸŒ Open Track
**Constraint:** No restrictions - any publicly available data allowed
- **Sentence-level Assessment:** ğŸ¥‡ **Champion**
- **Document-level Assessment:** ğŸ¥ˆ **Runner-up**

## ğŸ› ï¸ Technical Approach

Our winning solution leverages a sophisticated ensemble methodology combining multiple state-of-the-art Arabic language models:

### ğŸ¤– Model Architecture
- **AraBERT v2** variants with different configurations
- **CAMeLBERT** for enhanced Arabic understanding
- **AraELECTRA** for improved efficiency
- **mALBERT** for multilingual capabilities

### ğŸ§  Ensemble Strategy
- **Confidence-based selection** for optimal predictions
- **Majority voting** for robust decision making
- **Weighted averaging** for balanced performance
- **Cross-validation** for reliable model assessment

### ğŸ“ˆ Key Features
- Advanced preprocessing for Arabic text normalization
- Multiple training strategies (ordinal, OLL-15)
- Data augmentation techniques
- Comprehensive evaluation metrics

## ğŸ“ Repository Structure

```
BAREC2025/
â”œâ”€â”€ ğŸ“Š DataSets/                    # Training and test datasets
â”‚   â”œâ”€â”€ 72,000K_Train_Data.csv
â”‚   â”œâ”€â”€ blind_test_dataset.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ ğŸ“š Notebooks/                   # Model training notebooks
â”‚   â”œâ”€â”€ ARAELECTRA.ipynb
â”‚   â”œâ”€â”€ CAMELBERT.ipynb
â”‚   â”œâ”€â”€ barec_arabert_oll15.ipynb
â”‚   â””â”€â”€ ...
â”œâ”€â”€ ğŸ”§ Core Scripts/
â”‚   â”œâ”€â”€ ensemble_by_max_confidence.py
â”‚   â”œâ”€â”€ voting.py
â”‚   â”œâ”€â”€ avg.py
â”‚   â””â”€â”€ differentPrediction.py
â””â”€â”€ ğŸ“‹ Analysis Tools/
    â”œâ”€â”€ prediction_visualization.py
    â””â”€â”€ combine_conf.py
```

## ğŸ›ï¸ Key Components

### 1. Ensemble Methods (`ensemble_by_max_confidence.py`)
Implements confidence-based ensemble selection for optimal prediction accuracy.

```python
# Selects predictions based on model confidence scores
def ensemble_by_max_confidence_simple(file1_path, file2_path, output_path)
```

### 2. Voting Systems (`voting.py`)
Provides majority and average voting mechanisms for robust decision making.

```python
# Supports both majority and average voting strategies
def voting_ensemble(file_paths, output_file, method='majority')
```

### 3. Prediction Analysis (`differentPrediction.py`)
Analyzes prediction differences and model agreement patterns.

```python
# Comprehensive prediction comparison and analysis
def count_prediction_differences(file1, file2, show_diffs=False)
```

## ğŸƒâ€â™‚ï¸ Quick Start

### Prerequisites
```bash
pip install pandas numpy transformers torch scikit-learn
```

### Running the Ensemble
```python
# Confidence-based ensemble
from ensemble_by_max_confidence import ensemble_by_max_confidence_simple

result = ensemble_by_max_confidence_simple(
    "model1_predictions.csv", 
    "model2_predictions.csv", 
    "ensemble_output.csv"
)

# Voting ensemble
from voting import voting_ensemble

file_paths = ["pred1.csv", "pred2.csv", "pred3.csv"]
final_pred = voting_ensemble(file_paths, "final_prediction.csv", method='majority')
```


## ğŸ¤ Contributing

We welcome contributions to improve Arabic readability assessment. Please feel free to:

- Open issues for bug reports or feature requests
- Submit pull requests for improvements
- Share your own strategies
- Contribute additional Arabic language models


## ğŸ”— Links

- **Competition Website:** [BAREC 2025 Shared Task](https://barec.camel-lab.com/sharedtask2025)
- **CodaBench Platform:** [Competition Results](https://barec.camel-lab.com/sharedtask2025)
- **BAREC Corpus:** [Official Dataset](https://barec.camel-lab.com/)
- **SAMER Corpus:** [Additional Training Data](https://samer.camel-lab.com/)

## ğŸ† Team

This championship solution was developed by our dedicated team of researchers specializing in Arabic NLP and machine learning.

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

<div align="center">

**ğŸ‰ Celebrating Excellence in Arabic Readability Assessment ğŸ‰**

*BAREC 2025 Champions - Advancing Arabic NLP Research*

[![GitHub stars](https://img.shields.io/github/stars/Mohamedbasem1/BAREC_2025?style=social)](https://github.com/Mohamedbasem1/BAREC_2025)
[![GitHub forks](https://img.shields.io/github/forks/Mohamedbasem1/BAREC_2025?style=social)](https://github.com/Mohamedbasem1/BAREC_2025)

</div>
