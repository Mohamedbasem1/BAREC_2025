{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5041d5f6",
   "metadata": {
    "id": "5041d5f6"
   },
   "source": [
    "# BAREC Shared Task 2025: Arabic Sentence Readability Classification\n",
    "\n",
    "This notebook implements a sentence-level readability classification model using XLM-RoBERTa Large Arabic QA for the BAREC Shared Task 2025.\n",
    "\n",
    "## Task Overview\n",
    "- **Goal**: Predict readability level of Arabic sentences on a 1-19 scale\n",
    "- **Model**: XLM-RoBERTa Large Arabic QA 8-bit (multilingual model fine-tuned for Arabic QA with efficient 8-bit quantization)\n",
    "- **Target Metric**: Quadratic Weighted Kappa (QWK) > 81\n",
    "- **Data**: Train on Combined_dataset.csv, validate on test.csv, predict on blind_test_dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64b00eea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "64b00eea",
    "outputId": "6b6236f2-b68a-4312-c838-b4494a5aefe0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (4.53.3)\n",
      "Requirement already satisfied: torch in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (2.7.0+cu128)\n",
      "Requirement already satisfied: pandas in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.3.2)\n",
      "Requirement already satisfied: matplotlib in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (3.8.2)\n",
      "Requirement already satisfied: seaborn in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: tqdm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: optuna in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (4.4.0)\n",
      "Requirement already satisfied: accelerate in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.9.0)\n",
      "Requirement already satisfied: datasets in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (4.0.0)\n",
      "Requirement already satisfied: evaluate in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.4.5)\n",
      "Requirement already satisfied: tiktoken in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: sentencepiece in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.2.0)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.33.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.7.1.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (9.7.1.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (1.13.0.11)\n",
      "Requirement already satisfied: triton==3.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (3.3.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from triton==3.3.0->torch) (78.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from optuna) (1.16.4)\n",
      "Requirement already satisfied: colorlog in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from optuna) (2.0.41)\n",
      "Requirement already satisfied: psutil in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.14)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: Mako in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: tomli in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (2.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (2025.7.14)\n",
      "Requirement already satisfied: greenlet>=1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install transformers torch pandas numpy scikit-learn matplotlib seaborn tqdm optuna accelerate datasets evaluate tiktoken sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c5bf04c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4c5bf04c",
    "outputId": "699cc78c-d4d4-4bc2-8485-4fcfd83b673e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA L40S\n",
      "GPU Memory: 44.5 GB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModel, AutoConfig, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, mean_absolute_error, confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import optuna\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47536df",
   "metadata": {
    "id": "c47536df"
   },
   "source": [
    "## 1. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c56ac062",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "id": "c56ac062",
    "outputId": "f55947a5-3d64-4ab1-f4b2-44637e6110c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading Datasets ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Sizes:\n",
      "Train: 62,155 sentences (from Combined_dataset.csv)\n",
      "Dev:   7,286 sentences (from test.csv)\n",
      "Blind Test: 3,420 sentences (for final prediction)\n",
      "\n",
      "Column names (Train):\n",
      "['ID', 'Sentence_orignial ', 'cleaned_sentence', 'Sentence', 'Word_Count', 'Readability_Level', 'Readability_Level_19', 'Text_Class', 'Domain', 'Source', 'Annotator']\n",
      "\n",
      "First few rows (Train):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sentence_orignial</th>\n",
       "      <th>cleaned_sentence</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Word_Count</th>\n",
       "      <th>Readability_Level</th>\n",
       "      <th>Readability_Level_19</th>\n",
       "      <th>Text_Class</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Source</th>\n",
       "      <th>Annotator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10100290001</td>\n",
       "      <td>مجلة كل الأولاد وكل البنات</td>\n",
       "      <td>مجلة كل الأولاد وكل البنات</td>\n",
       "      <td>مجلة كل ال+ أولاد و+ كل ال+ بنات</td>\n",
       "      <td>5</td>\n",
       "      <td>7-zay</td>\n",
       "      <td>7</td>\n",
       "      <td>Foundational</td>\n",
       "      <td>Arts &amp; Humanities</td>\n",
       "      <td>Majed</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10100290002</td>\n",
       "      <td>ماجد</td>\n",
       "      <td>ماجد</td>\n",
       "      <td>ماجد</td>\n",
       "      <td>1</td>\n",
       "      <td>1-alif</td>\n",
       "      <td>1</td>\n",
       "      <td>Foundational</td>\n",
       "      <td>Arts &amp; Humanities</td>\n",
       "      <td>Majed</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10100290003</td>\n",
       "      <td>الأربعاء 21 يناير 1987</td>\n",
       "      <td>الأربعاء 21 يناير 1987</td>\n",
       "      <td>ال+ أربعاء 21 يناير 1987</td>\n",
       "      <td>4</td>\n",
       "      <td>8-Ha</td>\n",
       "      <td>8</td>\n",
       "      <td>Foundational</td>\n",
       "      <td>Arts &amp; Humanities</td>\n",
       "      <td>Majed</td>\n",
       "      <td>A3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10100290004</td>\n",
       "      <td>الموافق 21 جمادى الأول 1407هــ</td>\n",
       "      <td>الموافق 21 جمادى الأول 1407هــ</td>\n",
       "      <td>ال+ موافق 21 جماد +ي ال+ أول 1407هــ</td>\n",
       "      <td>6</td>\n",
       "      <td>7-zay</td>\n",
       "      <td>7</td>\n",
       "      <td>Foundational</td>\n",
       "      <td>Arts &amp; Humanities</td>\n",
       "      <td>Majed</td>\n",
       "      <td>A3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10100290005</td>\n",
       "      <td>السنة الثامنة</td>\n",
       "      <td>السنة الثامنة</td>\n",
       "      <td>ال+ سنة ال+ ثامنة</td>\n",
       "      <td>2</td>\n",
       "      <td>5-ha</td>\n",
       "      <td>5</td>\n",
       "      <td>Foundational</td>\n",
       "      <td>Arts &amp; Humanities</td>\n",
       "      <td>Majed</td>\n",
       "      <td>A4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID              Sentence_orignial   \\\n",
       "0  10100290001      مجلة كل الأولاد وكل البنات   \n",
       "1  10100290002                            ماجد   \n",
       "2  10100290003          الأربعاء 21 يناير 1987   \n",
       "3  10100290004  الموافق 21 جمادى الأول 1407هــ   \n",
       "4  10100290005                   السنة الثامنة   \n",
       "\n",
       "                 cleaned_sentence                              Sentence  \\\n",
       "0      مجلة كل الأولاد وكل البنات      مجلة كل ال+ أولاد و+ كل ال+ بنات   \n",
       "1                            ماجد                                  ماجد   \n",
       "2          الأربعاء 21 يناير 1987              ال+ أربعاء 21 يناير 1987   \n",
       "3  الموافق 21 جمادى الأول 1407هــ  ال+ موافق 21 جماد +ي ال+ أول 1407هــ   \n",
       "4                   السنة الثامنة                     ال+ سنة ال+ ثامنة   \n",
       "\n",
       "   Word_Count Readability_Level  Readability_Level_19    Text_Class  \\\n",
       "0           5             7-zay                     7  Foundational   \n",
       "1           1            1-alif                     1  Foundational   \n",
       "2           4              8-Ha                     8  Foundational   \n",
       "3           6             7-zay                     7  Foundational   \n",
       "4           2              5-ha                     5  Foundational   \n",
       "\n",
       "              Domain Source Annotator  \n",
       "0  Arts & Humanities  Majed        A2  \n",
       "1  Arts & Humanities  Majed        A2  \n",
       "2  Arts & Humanities  Majed        A3  \n",
       "3  Arts & Humanities  Majed        A3  \n",
       "4  Arts & Humanities  Majed        A4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load datasets\n",
    "print(\"--- Loading Datasets ---\")\n",
    "train_df = pd.read_csv('D3TOK_Preprocessed_BAREC_Dataset2.csv')\n",
    "dev_df = pd.read_csv('D3TOK_test.csv') # Using test.csv as the new dev/validation set\n",
    "blind_test_df = pd.read_csv('D3TOK_blind_test.csv') # New blind test set for final prediction\n",
    "\n",
    "print(f\"Dataset Sizes:\")\n",
    "print(f\"Train: {len(train_df):,} sentences (from Combined_dataset.csv)\")\n",
    "print(f\"Dev:   {len(dev_df):,} sentences (from test.csv)\")\n",
    "print(f\"Blind Test: {len(blind_test_df):,} sentences (for final prediction)\")\n",
    "\n",
    "print(\"\\nColumn names (Train):\")\n",
    "print(train_df.columns.tolist())\n",
    "\n",
    "print(\"\\nFirst few rows (Train):\")\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6706f760",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6706f760",
    "outputId": "df1695c8-770e-43be-95d8-4b957283dd39"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Readability_Level_7'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pandas/core/indexes/base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Readability_Level_7'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m axes[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_ylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# 7-level distribution\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m axes[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mhist(\u001b[43mtrain_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mReadability_Level_7\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlightgreen\u001b[39m\u001b[38;5;124m'\u001b[39m, edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m axes[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Set: 7-Level Readability Distribution\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m axes[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mset_xlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReadability Level (1-7)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pandas/core/indexes/base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3796\u001b[0m     ):\n\u001b[1;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Readability_Level_7'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analyze readability level distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 19-level distribution\n",
    "axes[0,0].hist(train_df['Readability_Level_19'], bins=19, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0,0].set_title('Train Set: 19-Level Readability Distribution')\n",
    "axes[0,0].set_xlabel('Readability Level (1-19)')\n",
    "axes[0,0].set_ylabel('Count')\n",
    "\n",
    "# 7-level distribution\n",
    "axes[0,1].hist(train_df['Readability_Level_7'], bins=7, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "axes[0,1].set_title('Train Set: 7-Level Readability Distribution')\n",
    "axes[0,1].set_xlabel('Readability Level (1-7)')\n",
    "axes[0,1].set_ylabel('Count')\n",
    "\n",
    "# Word count distribution\n",
    "axes[1,0].hist(train_df['Word_Count'], bins=50, alpha=0.7, color='salmon', edgecolor='black')\n",
    "axes[1,0].set_title('Train Set: Word Count Distribution')\n",
    "axes[1,0].set_xlabel('Word Count')\n",
    "axes[1,0].set_ylabel('Count')\n",
    "axes[1,0].set_xlim(0, 50)  # Focus on reasonable range\n",
    "\n",
    "# Sentence length analysis\n",
    "train_df['Sentence_Length'] = train_df['Sentence'].str.len()\n",
    "axes[1,1].hist(train_df['Sentence_Length'], bins=50, alpha=0.7, color='orange', edgecolor='black')\n",
    "axes[1,1].set_title('Train Set: Sentence Length Distribution')\n",
    "axes[1,1].set_xlabel('Sentence Length (characters)')\n",
    "axes[1,1].set_ylabel('Count')\n",
    "axes[1,1].set_xlim(0, 200)  # Focus on reasonable range\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(\"\\nReadability Level Statistics (19-scale):\")\n",
    "print(train_df['Readability_Level_19'].describe())\n",
    "\n",
    "print(\"\\nWord Count Statistics:\")\n",
    "print(train_df['Word_Count'].describe())\n",
    "\n",
    "print(\"\\nSentence Length Statistics:\")\n",
    "print(train_df['Sentence_Length'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c209533a",
   "metadata": {
    "id": "c209533a"
   },
   "source": [
    "## 2. Evaluation Metrics Implementation\n",
    "\n",
    "We'll implement all required metrics including Quadratic Weighted Kappa (QWK), multiple accuracy measures, and MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6acbf423",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6acbf423",
    "outputId": "a3f3f474-4910-4799-ba54-615da9706a37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing metrics implementation...\n",
      "\n",
      "Test Metrics (Dummy Data)\n",
      "=========================\n",
      "Quadratic Weighted Kappa (QWK): 0.9827\n",
      "Accuracy@19 (Exact Match):       0.7000\n",
      "Accuracy@7:                      0.8000\n",
      "Accuracy@5:                      1.0000\n",
      "Accuracy@3:                      1.0000\n",
      "±1 Accuracy (Adjacent):          1.0000\n",
      "Mean Absolute Error (MAE):       0.3000\n"
     ]
    }
   ],
   "source": [
    "def quadratic_weighted_kappa(y_true, y_pred, labels=None):\n",
    "    \"\"\"\n",
    "    Calculate Quadratic Weighted Kappa (QWK) score.\n",
    "    \"\"\"\n",
    "    if labels is None:\n",
    "        labels = np.unique(np.concatenate([y_true, y_pred]))\n",
    "\n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    n_classes = len(labels)\n",
    "\n",
    "    # Create weight matrix for quadratic weighting\n",
    "    weights = np.zeros((n_classes, n_classes))\n",
    "    for i in range(n_classes):\n",
    "        for j in range(n_classes):\n",
    "            weights[i, j] = ((i - j) ** 2) / ((n_classes - 1) ** 2)\n",
    "\n",
    "    # Calculate expected matrix\n",
    "    row_marginals = cm.sum(axis=1)\n",
    "    col_marginals = cm.sum(axis=0)\n",
    "    total = cm.sum()\n",
    "    expected = np.outer(row_marginals, col_marginals) / total\n",
    "\n",
    "    # Calculate QWK\n",
    "    numerator = np.sum(weights * cm)\n",
    "    denominator = np.sum(weights * expected)\n",
    "\n",
    "    if denominator == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return 1 - (numerator / denominator)\n",
    "\n",
    "def collapse_levels(y, target_levels):\n",
    "    \"\"\"\n",
    "    Collapse 19-level readability to fewer levels.\n",
    "    \"\"\"\n",
    "    if target_levels == 7:\n",
    "        # Map 1-19 to 1-7\n",
    "        mapping = {\n",
    "            1: 1, 2: 1, 3: 1,\n",
    "            4: 2, 5: 2, 6: 2,\n",
    "            7: 3, 8: 3, 9: 3,\n",
    "            10: 4, 11: 4, 12: 4,\n",
    "            13: 5, 14: 5, 15: 5,\n",
    "            16: 6, 17: 6, 18: 6,\n",
    "            19: 7\n",
    "        }\n",
    "    elif target_levels == 5:\n",
    "        # Map 1-19 to 1-5\n",
    "        mapping = {\n",
    "            1: 1, 2: 1, 3: 1, 4: 1,\n",
    "            5: 2, 6: 2, 7: 2, 8: 2,\n",
    "            9: 3, 10: 3, 11: 3, 12: 3,\n",
    "            13: 4, 14: 4, 15: 4, 16: 4,\n",
    "            17: 5, 18: 5, 19: 5\n",
    "        }\n",
    "    elif target_levels == 3:\n",
    "        # Map 1-19 to 1-3\n",
    "        mapping = {\n",
    "            1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1,\n",
    "            8: 2, 9: 2, 10: 2, 11: 2, 12: 2, 13: 2,\n",
    "            14: 3, 15: 3, 16: 3, 17: 3, 18: 3, 19: 3\n",
    "        }\n",
    "    else:\n",
    "        return y\n",
    "\n",
    "    return np.array([mapping.get(level, level) for level in y])\n",
    "\n",
    "def adjacent_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate ±1 accuracy (predictions within ±1 of true label).\n",
    "    \"\"\"\n",
    "    return np.mean(np.abs(y_true - y_pred) <= 1)\n",
    "\n",
    "def calculate_all_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate all required evaluation metrics.\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "\n",
    "    # Main metric: Quadratic Weighted Kappa\n",
    "    metrics['QWK'] = quadratic_weighted_kappa(y_true, y_pred)\n",
    "\n",
    "    # Accuracy@19 (exact match on 19-level scale)\n",
    "    metrics['Acc19'] = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # Accuracies on collapsed scales\n",
    "    for levels in [7, 5, 3]:\n",
    "        y_true_collapsed = collapse_levels(y_true, levels)\n",
    "        y_pred_collapsed = collapse_levels(y_pred, levels)\n",
    "        metrics[f'Acc{levels}'] = accuracy_score(y_true_collapsed, y_pred_collapsed)\n",
    "\n",
    "    # ±1 Accuracy (Adjacent Accuracy)\n",
    "    metrics['Adjacent_Acc'] = adjacent_accuracy(y_true, y_pred)\n",
    "\n",
    "    # Average Distance / MAE\n",
    "    metrics['MAE'] = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def print_metrics(metrics, title=\"Evaluation Metrics\"):\n",
    "    \"\"\"\n",
    "    Pretty print evaluation metrics.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{title}\")\n",
    "    print(\"=\" * len(title))\n",
    "    print(f\"Quadratic Weighted Kappa (QWK): {metrics['QWK']:.4f}\")\n",
    "    print(f\"Accuracy@19 (Exact Match):       {metrics['Acc19']:.4f}\")\n",
    "    print(f\"Accuracy@7:                      {metrics['Acc7']:.4f}\")\n",
    "    print(f\"Accuracy@5:                      {metrics['Acc5']:.4f}\")\n",
    "    print(f\"Accuracy@3:                      {metrics['Acc3']:.4f}\")\n",
    "    print(f\"±1 Accuracy (Adjacent):          {metrics['Adjacent_Acc']:.4f}\")\n",
    "    print(f\"Mean Absolute Error (MAE):       {metrics['MAE']:.4f}\")\n",
    "\n",
    "# Test the metrics with dummy data\n",
    "print(\"Testing metrics implementation...\")\n",
    "y_test = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "y_pred_test = np.array([1, 2, 4, 4, 5, 7, 7, 8, 9, 11])\n",
    "test_metrics = calculate_all_metrics(y_test, y_pred_test)\n",
    "print_metrics(test_metrics, \"Test Metrics (Dummy Data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aadb68d",
   "metadata": {
    "id": "5aadb68d"
   },
   "source": [
    "## 3. XLM-RoBERTa Large Arabic QA Model Implementation\n",
    "\n",
    "We'll use the XLM-RoBERTa Large Arabic QA model from HuggingFace for Arabic text classification. This model is based on XLM-RoBERTa Large and has been fine-tuned for Arabic QA tasks, making it highly effective for Arabic language understanding. The 8-bit quantization provides efficiency while maintaining performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a51b22",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449,
     "referenced_widgets": [
      "a7a9047f2bd240bca87bd1dcf23929b1",
      "36ca08b54833419e90b2054134268c5a",
      "b5186d0efa964427b42b2c8fd14d7e5e",
      "a69a0952c5d748dda6c3b50c081095de",
      "f70a9188d653421b95a2da6a8d6a3a87",
      "9d480fdb6bbe4d2c80c54b86e4d690a2",
      "727d8c42596c40bd870816f5dfcca4f0",
      "fcec51c756164065841cc067c7aa4b59",
      "bc2fbf43fede44e9a6be4523aec5a417",
      "80395a9cb6f64658b27f1bf40e3b45bf",
      "fb0f09551f1642cfa0b65b583c9d1fe1",
      "486e1db65e254a6582c4042fc2c59c1b",
      "56a72d516e56418cb7de5daba4f14a79",
      "e7b3635399e446838105a9296327ee08",
      "d4653c75698a441894ea3493baf9a888",
      "960f5003d3d34540b3a983c0de62c8df",
      "3e063868493d44b18b5ba58f11355413",
      "2fba10200f8e425bb7e87e8556c6bc34",
      "5e606f805f8f42b1b669c176de3f8df8",
      "23abb601dedf432f8b2f9d364ee851e1",
      "3ce6076aaedf463b8ef63062b9e81dec",
      "88f21c7af6ee4573a763361842a43fd2",
      "9dca3a79419345e1a5690589ddf50675",
      "659738becc9c47f6af45a4ad972d0b95",
      "9595ecc2490f49ea966aaeb50609e289",
      "6df95b9811b74ddca25bc0f4257bc097",
      "b4c4660bb38d49859254d11b1c1ca3c1",
      "ea1507678c17416b8a6f139d4be09c76",
      "69380d6e06f849dba235c4dc48fecc92",
      "3d59c3414a9c453db798c20e097221c2",
      "489a28aa17dd4a81adc1ad0a0a34b560",
      "77b0e2a5a8564da0a2c90636bf16d359",
      "6b37cf27b89e4f83ae631e47beadd986",
      "d7ac15134fc8429083ce02fdccbd223d",
      "b4b47cc1be6b49bda4aca89ed81b32ef",
      "9263e531606a44f3bd6b164a79c5f789",
      "b825199285774f9383220106cf29207b",
      "10d50f9830624447856e59e78b7fb2b6",
      "1f502c61dd6c468ab83e6a6ebb61621f",
      "003e13f1e3b44f7fb7ba26757e630658",
      "78457311695943669e21049801e31e8d",
      "bf17000195434ddda79d600a63bedca1",
      "bbf2f4d9628149039ef6cb42fd9358c5",
      "081c45ee0cf74cebb4e7492fb14556a2",
      "45faf259c90245f3b261e29960df0380",
      "fe6ff805e4be4c04a01a1da7f76c37d3",
      "6bede89609594ae98e6e6ef0be5156b3",
      "33ccb32a03cb4e83bf4c45065d5fff4d",
      "995f2037536c4c8395f58dd17631b707",
      "cd5880991d7343feb96cf7dcf54e5220",
      "50d31da2c4014c5eb7c5a0bbd1a7a81a",
      "09156589ff404455a821aa7a68be1a62",
      "0c38c5efac824bf1b14651767b93abce",
      "0be998f74a474db190738216d69f0acb",
      "2cff338ff5f0423eb06f1730ae8e2c76"
     ]
    },
    "id": "40a51b22",
    "outputId": "9e969470-f827-4167-a616-f787c7f3fdae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading XLM-RoBERTa Large Arabic QA model: CAMeL-Lab/bert-base-arabic-camelbert-msa\n",
      "Tokenizer loaded successfully. Vocab size: 30000\n",
      "\n",
      "Sample text: مجلة كل ال+ أولاد و+ كل ال+ بنات\n",
      "Tokens: ['مجلة', 'كل', 'ا', '##ل', '+', 'أولاد', 'و', '+', 'كل', 'ا']...\n",
      "Token count: 13\n",
      "\n",
      "Analyzing tokenized sentence lengths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing: 100%|██████████| 1000/1000 [00:00<00:00, 16392.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token length stats (sample of 1000):\n",
      "Mean: 19.4\n",
      "Std:  15.2\n",
      "95th percentile: 49.0\n",
      "99th percentile: 72.0\n",
      "Max: 94\n",
      "\n",
      "✅ XLM-RoBERTa Large Arabic QA is optimized for Arabic and should provide excellent performance!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# XLM-RoBERTa Large Arabic QA model configuration\n",
    "# Using RichardErkhov/salti_-_xlm-roberta-large-arabic_qa-8bits - 8-bit quantized model optimized for Arabic QA tasks\n",
    "MODEL_NAME = \"RichardErkhov/salti_-_xlm-roberta-large-arabic_qa-8bits\"  # XLM-RoBERTa Large Arabic QA 8-bit model\n",
    "MAX_LENGTH = 128  # Maximum sequence length\n",
    "NUM_LABELS = 19   # 19 readability levels\n",
    "\n",
    "print(f\"Loading XLM-RoBERTa Large Arabic QA model: {MODEL_NAME}\")\n",
    "\n",
    "try:\n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "    print(f\"Tokenizer loaded successfully. Vocab size: {tokenizer.vocab_size}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading tokenizer: {e}\")\n",
    "    print(\"Trying alternative XLM-RoBERTa model...\")\n",
    "    # Fallback to standard XLM-RoBERTa large\n",
    "    MODEL_NAME = \"xlm-roberta-large\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "    print(f\"Fallback tokenizer loaded: {MODEL_NAME}\")\n",
    "\n",
    "# Test tokenization with Arabic text\n",
    "sample_text = train_df['Sentence'].iloc[0]\n",
    "print(f\"\\nSample text: {sample_text}\")\n",
    "tokens = tokenizer.tokenize(sample_text)\n",
    "print(f\"Tokens: {tokens[:10]}...\")  # Show first 10 tokens to avoid clutter\n",
    "print(f\"Token count: {len(tokens)}\")\n",
    "\n",
    "# Analyze sentence lengths after tokenization\n",
    "print(\"\\nAnalyzing tokenized sentence lengths...\")\n",
    "sample_sentences = train_df['Sentence'].head(1000).tolist()\n",
    "token_lengths = []\n",
    "\n",
    "for sentence in tqdm(sample_sentences, desc=\"Tokenizing\"):\n",
    "    try:\n",
    "        tokens = tokenizer.tokenize(sentence)\n",
    "        token_lengths.append(len(tokens))\n",
    "    except Exception as e:\n",
    "        print(f\"Error tokenizing sentence: {e}\")\n",
    "        token_lengths.append(0)\n",
    "\n",
    "token_lengths = np.array(token_lengths)\n",
    "print(f\"Token length stats (sample of 1000):\")\n",
    "print(f\"Mean: {token_lengths.mean():.1f}\")\n",
    "print(f\"Std:  {token_lengths.std():.1f}\")\n",
    "print(f\"95th percentile: {np.percentile(token_lengths, 95):.1f}\")\n",
    "print(f\"99th percentile: {np.percentile(token_lengths, 99):.1f}\")\n",
    "print(f\"Max: {token_lengths.max()}\")\n",
    "\n",
    "# Adjust MAX_LENGTH based on analysis\n",
    "if np.percentile(token_lengths, 95) > MAX_LENGTH:\n",
    "    print(f\"\\nWarning: 95th percentile ({np.percentile(token_lengths, 95):.1f}) > MAX_LENGTH ({MAX_LENGTH})\")\n",
    "    print(\"Consider increasing MAX_LENGTH for better performance\")\n",
    "    \n",
    "print(f\"\\n✅ XLM-RoBERTa Large Arabic QA is optimized for Arabic and should provide excellent performance!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d49bcd1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9d49bcd1",
    "outputId": "3188a491-a5e7-496a-b53f-c72d6f7170b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and dataset classes defined successfully!\n",
      "✅ Model updated to use XLM-RoBERTa Large Arabic QA with Cross Entropy Loss for classification.\n",
      "📊 Using Cross Entropy loss for discrete readability classification.\n",
      "🇸🇦 XLM-RoBERTa is specifically designed for Arabic and should excel at this classification task!\n"
     ]
    }
   ],
   "source": [
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "class ArabicReadabilityDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for Arabic readability classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, sentences, labels, tokenizer, max_length=128):\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = str(self.sentences[idx])\n",
    "        # Convert labels from 1-19 to 0-18 for classification\n",
    "        label = int(self.labels[idx]) - 1  # Convert to 0-indexed for classification\n",
    "\n",
    "        # Tokenize and encode\n",
    "        encoding = self.tokenizer(\n",
    "            sentence,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)  # Long tensor for classification\n",
    "        }\n",
    "\n",
    "class XLMRoBERTaForReadability(nn.Module):\n",
    "    \"\"\"\n",
    "    XLM-RoBERTa Large Arabic QA model for Arabic readability classification using Cross Entropy loss.\n",
    "    This version uses classification with 19 classes (levels 1-19) instead of regression.\n",
    "    Uses the 8-bit quantized model for efficiency.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name, num_labels=19, dropout_rate=0.1):  # num_labels=19 for classification\n",
    "        super(XLMRoBERTaForReadability, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "        # Load pre-trained XLM-RoBERTa Large Arabic QA model\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "        # Classification head (output 19 classes for readability levels 1-19)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)  # 19 outputs for classification\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "\n",
    "        # Use [CLS] token representation (pooler_output or last_hidden_state[:, 0])\n",
    "        if hasattr(outputs, 'pooler_output') and outputs.pooler_output is not None:\n",
    "            pooled_output = outputs.pooler_output\n",
    "        else:\n",
    "            pooled_output = outputs.last_hidden_state[:, 0]  # [CLS] token\n",
    "        \n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)  # Shape: (batch_size, 19)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            # Use Cross Entropy loss for classification\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits, labels)  # labels should be 0-18 (class indices)\n",
    "\n",
    "        # Return a standard SequenceClassifierOutput object\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "\n",
    "print(\"Model and dataset classes defined successfully!\")\n",
    "print(\"✅ Model updated to use XLM-RoBERTa Large Arabic QA with Cross Entropy Loss for classification.\")\n",
    "print(\"📊 Using Cross Entropy loss for discrete readability classification.\")\n",
    "print(\"🤖 XLM-RoBERTa Large with 8-bit quantization provides excellent Arabic understanding with efficiency!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2129e848",
   "metadata": {
    "id": "2129e848"
   },
   "source": [
    "## 4. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c12ed41b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c12ed41b",
    "outputId": "a2f96879-a109-46f1-ee03-43222a5d7f83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing datasets...\n",
      "Train: 62155 sentences\n",
      "Dev (Validation): 7286 sentences\n",
      "Blind Test (Prediction): 3420 sentences\n",
      "Train and Dev datasets created successfully!\n",
      "\n",
      "Sample input shape: torch.Size([128])\n",
      "Sample label: 6 (original: 7)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for training\n",
    "print(\"Preparing datasets...\")\n",
    "\n",
    "# Extract sentences and labels from the new dataframes\n",
    "train_sentences = train_df['Sentence'].tolist()\n",
    "train_labels = train_df['Readability_Level_19'].tolist()\n",
    "\n",
    "dev_sentences = dev_df['Sentence'].tolist()\n",
    "dev_labels = dev_df['Readability_Level_19'].tolist()\n",
    "\n",
    "# The blind test set only has sentences for prediction, no labels\n",
    "blind_test_sentences = blind_test_df['Sentence'].tolist()\n",
    "\n",
    "print(f\"Train: {len(train_sentences)} sentences\")\n",
    "print(f\"Dev (Validation): {len(dev_sentences)} sentences\")\n",
    "print(f\"Blind Test (Prediction): {len(blind_test_sentences)} sentences\")\n",
    "\n",
    "# Create datasets for training and validation\n",
    "# The blind test set will be handled separately later since it has no labels\n",
    "train_dataset = ArabicReadabilityDataset(\n",
    "    train_sentences, train_labels, tokenizer, MAX_LENGTH\n",
    ")\n",
    "dev_dataset = ArabicReadabilityDataset(\n",
    "    dev_sentences, dev_labels, tokenizer, MAX_LENGTH\n",
    ")\n",
    "\n",
    "print(\"Train and Dev datasets created successfully!\")\n",
    "\n",
    "# Test dataset loading\n",
    "sample = train_dataset[0]\n",
    "print(f\"\\nSample input shape: {sample['input_ids'].shape}\")\n",
    "print(f\"Sample label: {sample['labels']} (original: {train_labels[0]})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9567e1e",
   "metadata": {
    "id": "d9567e1e"
   },
   "source": [
    "## 5. Model Training with Hyperparameter Tuning\n",
    "\n",
    "We'll use Optuna for hyperparameter optimization to achieve QWK > 81."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d014124",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8d014124",
    "outputId": "3df145ac-2346-4672-d1eb-0c5bc1a00bdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training functions defined successfully!\n",
      "🚀 All training functions now use XLM-RoBERTa Large Arabic QA classification model with Cross Entropy loss.\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics_for_trainer(eval_pred):\n",
    "    \"\"\"\n",
    "    Compute metrics for the Trainer - adapted for classification with Cross Entropy.\n",
    "    \"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    # For classification, get the predicted class (highest logit)\n",
    "    predictions = np.argmax(predictions, axis=1)  # Get predicted class indices (0-18)\n",
    "    predictions = predictions + 1  # Convert back to 1-19 scale\n",
    "    labels = labels + 1  # Convert labels back to 1-19 scale\n",
    "\n",
    "    metrics = calculate_all_metrics(labels, predictions)\n",
    "    \n",
    "    # Add classification-specific metrics\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    metrics['accuracy'] = accuracy\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Objective function for Optuna hyperparameter optimization.\n",
    "    Uses dev dataset for training.\n",
    "    \"\"\"\n",
    "    # Suggest hyperparameters\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 5e-5, log=True)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [8, 16, 32])\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.3)\n",
    "    warmup_ratio = trial.suggest_float('warmup_ratio', 0.0, 0.2)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 0.0, 0.01)\n",
    "\n",
    "    # Create model with num_labels=19 for classification\n",
    "    model = XLMRoBERTaForReadability(\n",
    "        MODEL_NAME,\n",
    "        num_labels=19,  # 19 classes for readability levels 1-19\n",
    "        dropout_rate=dropout_rate\n",
    "    )\n",
    "\n",
    "    # Training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f'./results/trial_{trial.number}',\n",
    "        num_train_epochs=3,  # Reduced for faster optimization\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        warmup_ratio=warmup_ratio,\n",
    "        logging_steps=50,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=100,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=100,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"QWK\",\n",
    "        greater_is_better=True,\n",
    "        save_total_limit=1,\n",
    "        remove_unused_columns=False,\n",
    "        push_to_hub=False,\n",
    "        report_to=None,  # Disable wandb/tensorboard\n",
    "    )\n",
    "\n",
    "    # Create trainer - using dev_dataset for training\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=dev_dataset,  # Changed to dev_dataset\n",
    "        eval_dataset=dev_dataset,   # Keep as dev_dataset\n",
    "        compute_metrics=compute_metrics_for_trainer,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate\n",
    "    eval_results = trainer.evaluate()\n",
    "\n",
    "    # Clean up\n",
    "    del model\n",
    "    del trainer\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return eval_results['eval_QWK']\n",
    "\n",
    "# Quick training function for best hyperparameters\n",
    "def train_final_model(best_params, num_epochs=5):\n",
    "    \"\"\"\n",
    "    Train the final model with best hyperparameters.\n",
    "    Uses dev dataset for training with Cross Entropy classification.\n",
    "    \"\"\"\n",
    "    print(f\"Training final classification model with best parameters: {best_params}\")\n",
    "\n",
    "    # Create model with num_labels=19 for classification\n",
    "    model = XLMRoBERTaForReadability(\n",
    "        MODEL_NAME,\n",
    "        num_labels=19,  # 19 classes for readability levels 1-19\n",
    "        dropout_rate=best_params.get('dropout_rate', 0.1)\n",
    "    )\n",
    "\n",
    "    # Training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./final_model',\n",
    "        num_train_epochs=num_epochs,\n",
    "        per_device_train_batch_size=best_params.get('batch_size', 16),\n",
    "        per_device_eval_batch_size=best_params.get('batch_size', 16),\n",
    "        learning_rate=best_params.get('learning_rate', 2e-5),\n",
    "        weight_decay=best_params.get('weight_decay', 0.01),\n",
    "        warmup_ratio=best_params.get('warmup_ratio', 0.1),\n",
    "        logging_steps=50,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=100,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=100,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"QWK\",\n",
    "        greater_is_better=True,\n",
    "        save_total_limit=2,\n",
    "        remove_unused_columns=False,\n",
    "        push_to_hub=False,\n",
    "        report_to=None,\n",
    "    )\n",
    "\n",
    "    # Create trainer - using dev_dataset for training\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=dev_dataset,  # Changed to dev_dataset\n",
    "        eval_dataset=dev_dataset,   # Keep as dev_dataset\n",
    "        compute_metrics=compute_metrics_for_trainer,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    print(\"Starting classification training on dev dataset...\")\n",
    "    trainer.train()\n",
    "\n",
    "    return trainer\n",
    "\n",
    "print(\"Training functions defined successfully!\")\n",
    "print(\"🚀 All training functions now use XLM-RoBERTa Large Arabic QA classification model with Cross Entropy loss.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72762221",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 553
    },
    "id": "72762221",
    "outputId": "a8182bfa-202f-4b39-a5f7-066689d317e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting optimized classification training for high QWK performance...\n",
      "🎯 OPTIMIZED CLASSIFICATION TRAINING MODE: Using full training dataset for maximum performance\n",
      "Training samples: 62,155\n",
      "Validation samples: 7,286\n",
      "This will take longer but should achieve higher QWK scores!\n",
      "\n",
      "🚀 Starting optimized classification training with XLM-RoBERTa Large Arabic QA...\n",
      "Training optimized XLM-RoBERTa Large Arabic QA classification model with parameters: {'learning_rate': 2e-05, 'batch_size': 32, 'dropout_rate': 0.1, 'warmup_ratio': 0.1, 'weight_decay': 0.01, 'num_epochs': 8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Steps per epoch: 1942\n",
      "📊 Total training steps: 15536\n",
      "Starting optimized classification training on full dataset with XLM-RoBERTa Large Arabic QA...\n",
      "📊 Training on 62,155 samples\n",
      "📊 Validating on 7,286 samples\n",
      "🔄 Will train for 8 complete epochs\n",
      "🇸🇦 Using Arabic-specialized XLM-RoBERTa for optimal classification performance!\n",
      "📊 Using Cross Entropy Loss for discrete readability classification!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15544' max='15544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15544/15544 14:07, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Qwk</th>\n",
       "      <th>Acc19</th>\n",
       "      <th>Acc7</th>\n",
       "      <th>Acc5</th>\n",
       "      <th>Acc3</th>\n",
       "      <th>Adjacent Acc</th>\n",
       "      <th>Mae</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.489300</td>\n",
       "      <td>1.423711</td>\n",
       "      <td>0.793322</td>\n",
       "      <td>0.508921</td>\n",
       "      <td>0.661131</td>\n",
       "      <td>0.710678</td>\n",
       "      <td>0.805517</td>\n",
       "      <td>0.660994</td>\n",
       "      <td>1.205463</td>\n",
       "      <td>0.508921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.258600</td>\n",
       "      <td>1.295248</td>\n",
       "      <td>0.805151</td>\n",
       "      <td>0.555312</td>\n",
       "      <td>0.695169</td>\n",
       "      <td>0.732775</td>\n",
       "      <td>0.812929</td>\n",
       "      <td>0.692698</td>\n",
       "      <td>1.120093</td>\n",
       "      <td>0.555312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.085100</td>\n",
       "      <td>1.349929</td>\n",
       "      <td>0.792970</td>\n",
       "      <td>0.553253</td>\n",
       "      <td>0.697228</td>\n",
       "      <td>0.734834</td>\n",
       "      <td>0.807027</td>\n",
       "      <td>0.694894</td>\n",
       "      <td>1.145484</td>\n",
       "      <td>0.553253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.892600</td>\n",
       "      <td>1.371155</td>\n",
       "      <td>0.807270</td>\n",
       "      <td>0.555037</td>\n",
       "      <td>0.700659</td>\n",
       "      <td>0.742520</td>\n",
       "      <td>0.810870</td>\n",
       "      <td>0.701208</td>\n",
       "      <td>1.098408</td>\n",
       "      <td>0.555037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.718600</td>\n",
       "      <td>1.466725</td>\n",
       "      <td>0.809954</td>\n",
       "      <td>0.556547</td>\n",
       "      <td>0.700247</td>\n",
       "      <td>0.741559</td>\n",
       "      <td>0.814713</td>\n",
       "      <td>0.701620</td>\n",
       "      <td>1.084408</td>\n",
       "      <td>0.556547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.591900</td>\n",
       "      <td>1.594506</td>\n",
       "      <td>0.802872</td>\n",
       "      <td>0.543371</td>\n",
       "      <td>0.692698</td>\n",
       "      <td>0.735108</td>\n",
       "      <td>0.810870</td>\n",
       "      <td>0.697777</td>\n",
       "      <td>1.125721</td>\n",
       "      <td>0.543371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.478700</td>\n",
       "      <td>1.745386</td>\n",
       "      <td>0.796786</td>\n",
       "      <td>0.542136</td>\n",
       "      <td>0.695306</td>\n",
       "      <td>0.733461</td>\n",
       "      <td>0.804968</td>\n",
       "      <td>0.695992</td>\n",
       "      <td>1.144798</td>\n",
       "      <td>0.542136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.412100</td>\n",
       "      <td>1.783230</td>\n",
       "      <td>0.802930</td>\n",
       "      <td>0.542410</td>\n",
       "      <td>0.697228</td>\n",
       "      <td>0.734559</td>\n",
       "      <td>0.807851</td>\n",
       "      <td>0.700659</td>\n",
       "      <td>1.128054</td>\n",
       "      <td>0.542410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Optimized XLM-RoBERTa Large Arabic QA classification training completed!\n",
      "🎯 This should achieve much higher QWK scores on the test set.\n",
      "📈 Model trained on full dataset with proper train/dev split.\n",
      "🇸🇦 XLM-RoBERTa's Arabic specialization should provide excellent results!\n",
      "📊 Cross Entropy Loss provides discrete classification for readability levels!\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Optimized training for QWK > 81% with Cross Entropy Classification\n",
    "print(\"Starting optimized classification training for high QWK performance...\")\n",
    "\n",
    "# Use optimized hyperparameters based on XLM-RoBERTa research for classification\n",
    "optimized_params = {\n",
    "    'learning_rate': 2e-5,      # Appropriate learning rate for classification\n",
    "    'batch_size': 32,           # Larger batch size for stability with BERT\n",
    "    'dropout_rate': 0.1,        # Conservative dropout for XLM-RoBERTa\n",
    "    'warmup_ratio': 0.1,        # Warmup for stable training\n",
    "    'weight_decay': 0.01,       # Weight decay for regularization\n",
    "    'num_epochs': 8             # Optimal epochs for Arabic BERT models\n",
    "}\n",
    "\n",
    "print(\"🎯 OPTIMIZED CLASSIFICATION TRAINING MODE: Using full training dataset for maximum performance\")\n",
    "print(f\"Training samples: {len(train_dataset):,}\")\n",
    "print(f\"Validation samples: {len(dev_dataset):,}\")\n",
    "print(\"This will take longer but should achieve higher QWK scores!\")\n",
    "\n",
    "# Create optimized training function for CLASSIFICATION\n",
    "def train_optimized_model(params, num_epochs=8):\n",
    "    \"\"\"\n",
    "    Train the CLASSIFICATION model with optimized settings for high QWK performance.\n",
    "    Uses full training dataset and validates on dev dataset.\n",
    "    \"\"\"\n",
    "    print(f\"Training optimized XLM-RoBERTa Large Arabic QA classification model with parameters: {params}\")\n",
    "\n",
    "    # Create CLASSIFICATION model with 19 classes\n",
    "    model = XLMRoBERTaForReadability(\n",
    "        MODEL_NAME,\n",
    "        num_labels=19,  # 19 classes for classification (NOT 1 for regression!)\n",
    "        dropout_rate=params.get('dropout_rate', 0.1)\n",
    "    )\n",
    "\n",
    "    # Calculate total steps for better scheduling\n",
    "    steps_per_epoch = len(train_dataset) // params.get('batch_size', 32)\n",
    "    total_steps = steps_per_epoch * num_epochs\n",
    "    \n",
    "    print(f\"📊 Steps per epoch: {steps_per_epoch}\")\n",
    "    print(f\"📊 Total training steps: {total_steps}\")\n",
    "\n",
    "    # Optimized training arguments for XLM-RoBERTa classification\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./optimized_model',\n",
    "        num_train_epochs=num_epochs,\n",
    "        per_device_train_batch_size=params.get('batch_size', 32),\n",
    "        per_device_eval_batch_size=params.get('batch_size', 32),\n",
    "        learning_rate=params.get('learning_rate', 2e-5),\n",
    "        weight_decay=params.get('weight_decay', 0.01),\n",
    "        warmup_ratio=params.get('warmup_ratio', 0.1),\n",
    "        \n",
    "        # Modified logging and evaluation - less frequent to avoid early stopping\n",
    "        logging_steps=200,\n",
    "        eval_strategy=\"epoch\",          # Evaluate only at end of each epoch\n",
    "        save_strategy=\"epoch\",          # Save only at end of each epoch\n",
    "        \n",
    "        # Model selection\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"QWK\",\n",
    "        greater_is_better=True,\n",
    "        save_total_limit=3,\n",
    "        \n",
    "        # Optimization settings\n",
    "        dataloader_drop_last=False,\n",
    "        remove_unused_columns=False,\n",
    "        push_to_hub=False,\n",
    "        report_to=None,\n",
    "        \n",
    "        # Advanced settings for better performance with XLM-RoBERTa classification\n",
    "        gradient_accumulation_steps=1,  # Standard for BERT-based models\n",
    "        fp16=True,                # Use mixed precision for speed\n",
    "        seed=42,\n",
    "    )\n",
    "\n",
    "    # Create trainer - using FULL training dataset with dev validation\n",
    "    # Removed EarlyStoppingCallback to ensure full training\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,    # Use FULL training dataset\n",
    "        eval_dataset=dev_dataset,       # Validate on dev dataset\n",
    "        compute_metrics=compute_metrics_for_trainer,\n",
    "        # No early stopping callback - train for full epochs\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    print(\"Starting optimized classification training on full dataset with XLM-RoBERTa Large Arabic QA...\")\n",
    "    print(f\"📊 Training on {len(train_dataset):,} samples\")\n",
    "    print(f\"📊 Validating on {len(dev_dataset):,} samples\")\n",
    "    print(f\"🔄 Will train for {num_epochs} complete epochs\")\n",
    "    print(\"🇸🇦 Using Arabic-specialized XLM-RoBERTa for optimal classification performance!\")\n",
    "    print(\"📊 Using Cross Entropy Loss for discrete readability classification!\")\n",
    "    trainer.train()\n",
    "\n",
    "    return trainer\n",
    "\n",
    "# Train with optimized parameters\n",
    "print(\"\\n🚀 Starting optimized classification training with XLM-RoBERTa Large Arabic QA...\")\n",
    "trainer = train_optimized_model(optimized_params, num_epochs=8)\n",
    "\n",
    "print(\"\\n✅ Optimized XLM-RoBERTa Large Arabic QA classification training completed!\")\n",
    "print(\"🎯 This should achieve much higher QWK scores on the test set.\")\n",
    "print(\"📈 Model trained on full dataset with proper train/dev split.\")\n",
    "print(\"🇸🇦 XLM-RoBERTa's Arabic specialization should provide excellent results!\")\n",
    "print(\"📊 Cross Entropy Loss provides discrete classification for readability levels!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b524cdd",
   "metadata": {
    "id": "4b524cdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter optimization ready for XLM-RoBERTa Large Arabic QA Regression!\n",
      "⚠️  Note: This will take 1-3 hours but should find parameters for QWK > 81%\n",
      "\n",
      "To run optimization, uncomment the lines below:\n",
      "# study = run_hyperparameter_optimization(n_trials=15, timeout_hours=2)\n",
      "# best_params = study.best_params\n",
      "# trainer = train_optimized_model(best_params, num_epochs=best_params.get('num_epochs', 4))\n",
      "\n",
      "💡 Alternative: Use these recommended parameters without optimization:\n",
      "Parameters: {'learning_rate': 2e-05, 'batch_size': 32, 'dropout_rate': 0.1, 'warmup_ratio': 0.1, 'weight_decay': 0.01, 'num_epochs': 4}\n",
      "These are optimized for MaraBERT regression and often achieve QWK > 81%\n",
      "🇸🇦 MaraBERT's Arabic specialization should provide excellent performance!\n",
      "📊 MSE Loss enables smooth continuous readability predictions!\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Hyperparameter optimization for QWK > 81% with Cross Entropy Classification\n",
    "# Run this cell for advanced optimization (takes longer but finds best parameters)\n",
    "\n",
    "def run_hyperparameter_optimization(n_trials=15, timeout_hours=3):\n",
    "    \"\"\"\n",
    "    Run hyperparameter optimization to find best parameters for QWK > 81% using classification\n",
    "    \"\"\"\n",
    "    print(\"🔍 Starting hyperparameter optimization for XLM-RoBERTa Large Arabic QA Classification QWK > 81%...\")\n",
    "    print(f\"Will run {n_trials} trials with {timeout_hours} hour timeout\")\n",
    "    \n",
    "    # Updated objective function with better parameter ranges for XLM-RoBERTa classification\n",
    "    def objective_optimized(trial):\n",
    "        # Suggest hyperparameters with optimized ranges for XLM-RoBERTa classification\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-5, 4e-5, log=True)\n",
    "        batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
    "        dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.3)\n",
    "        warmup_ratio = trial.suggest_float('warmup_ratio', 0.05, 0.2)\n",
    "        weight_decay = trial.suggest_float('weight_decay', 0.005, 0.02)\n",
    "        num_epochs = trial.suggest_int('num_epochs', 3, 5)\n",
    "\n",
    "        # Create CLASSIFICATION model with 19 classes\n",
    "        model = XLMRoBERTaForReadability(\n",
    "            MODEL_NAME,\n",
    "            num_labels=19,  # 19 classes for classification\n",
    "            dropout_rate=dropout_rate\n",
    "        )\n",
    "\n",
    "        # Training arguments for optimization\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=f'./optuna_trials/trial_{trial.number}',\n",
    "            num_train_epochs=num_epochs,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            learning_rate=learning_rate,\n",
    "            weight_decay=weight_decay,\n",
    "            warmup_ratio=warmup_ratio,\n",
    "            logging_steps=200,\n",
    "            eval_strategy=\"steps\",\n",
    "            eval_steps=300,\n",
    "            save_strategy=\"steps\",\n",
    "            save_steps=300,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"QWK\",\n",
    "            greater_is_better=True,\n",
    "            save_total_limit=1,\n",
    "            remove_unused_columns=False,\n",
    "            push_to_hub=False,\n",
    "            report_to=None,\n",
    "            fp16=True,\n",
    "            seed=42,\n",
    "        )\n",
    "\n",
    "        # Create trainer with FULL training dataset\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,    # Full training dataset\n",
    "            eval_dataset=dev_dataset,       # Dev dataset for validation\n",
    "            compute_metrics=compute_metrics_for_trainer,\n",
    "            callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "        )\n",
    "\n",
    "        # Train and evaluate\n",
    "        trainer.train()\n",
    "        eval_results = trainer.evaluate()\n",
    "\n",
    "        # Clean up\n",
    "        del model\n",
    "        del trainer\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        return eval_results['eval_QWK']\n",
    "\n",
    "    # Create and run study\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective_optimized, n_trials=n_trials, timeout=timeout_hours*3600)\n",
    "\n",
    "    print(f\"\\n🎉 Optimization completed!\")\n",
    "    print(f\"📊 Best trial: {study.best_trial.number}\")\n",
    "    print(f\"🎯 Best QWK: {study.best_value:.4f}\")\n",
    "    print(f\"⚙️  Best parameters: {study.best_params}\")\n",
    "\n",
    "    return study\n",
    "\n",
    "# Uncomment the lines below to run hyperparameter optimization\n",
    "print(\"Hyperparameter optimization ready for XLM-RoBERTa Large Arabic QA Classification!\")\n",
    "print(\"⚠️  Note: This will take 1-3 hours but should find parameters for QWK > 81%\")\n",
    "print(\"\\nTo run optimization, uncomment the lines below:\")\n",
    "print(\"# study = run_hyperparameter_optimization(n_trials=15, timeout_hours=2)\")\n",
    "print(\"# best_params = study.best_params\")\n",
    "print(\"# trainer = train_optimized_model(best_params, num_epochs=best_params.get('num_epochs', 4))\")\n",
    "\n",
    "# Quick option: Use these pre-researched parameters that often work well with XLM-RoBERTa classification\n",
    "recommended_params = {\n",
    "    'learning_rate': 2e-5,      # Appropriate for classification\n",
    "    'batch_size': 32,\n",
    "    'dropout_rate': 0.1,\n",
    "    'warmup_ratio': 0.1,\n",
    "    'weight_decay': 0.01,\n",
    "    'num_epochs': 4\n",
    "}\n",
    "\n",
    "print(f\"\\n💡 Alternative: Use these recommended parameters without optimization:\")\n",
    "print(f\"Parameters: {recommended_params}\")\n",
    "print(\"These are optimized for XLM-RoBERTa classification and often achieve QWK > 81%\")\n",
    "print(\"🇸🇦 XLM-RoBERTa's Arabic specialization should provide excellent performance!\")\n",
    "print(\"📊 Cross Entropy Loss enables discrete classification for readability levels!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b78dd1",
   "metadata": {
    "id": "b6b78dd1"
   },
   "source": [
    "## 6. Model Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79e71f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluating XLM-RoBERTa Large Arabic QA Classification Model on Development Set (test.csv) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='228' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 18/228 00:00 < 00:03, 63.90 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XLM-RoBERTa Large Arabic QA Classification Development Set Results (using test.csv)\n",
      "=====================================================================\n",
      "Quadratic Weighted Kappa (QWK): 0.8100\n",
      "Accuracy@19 (Exact Match):       0.5565\n",
      "Accuracy@7:                      0.7002\n",
      "Accuracy@5:                      0.7416\n",
      "Accuracy@3:                      0.8147\n",
      "±1 Accuracy (Adjacent):          0.7016\n",
      "Mean Absolute Error (MAE):       1.0844\n",
      "\n",
      "Blind test dataset created with 3420 samples.\n",
      "\n",
      "--- Generating classification predictions for the blind test set ---\n",
      "Generated 3420 classification predictions.\n",
      "\n",
      "📊 XLM-RoBERTa Large Arabic QA Classification Prediction Confidence Analysis:\n",
      "   Mean confidence: 0.753\n",
      "   Std confidence:  0.205\n",
      "   Min confidence:  0.161\n",
      "   Max confidence:  0.998\n",
      "\n",
      "📈 Classification Prediction Distribution:\n",
      "   Level  1:   17 predictions (  0.5%)\n",
      "   Level  2:   19 predictions (  0.6%)\n",
      "   Level  3:   79 predictions (  2.3%)\n",
      "   Level  4:   32 predictions (  0.9%)\n",
      "   Level  5:  188 predictions (  5.5%)\n",
      "   Level  6:   60 predictions (  1.8%)\n",
      "   Level  7:  283 predictions (  8.3%)\n",
      "   Level  8:  251 predictions (  7.3%)\n",
      "   Level  9:   83 predictions (  2.4%)\n",
      "   Level 10:  547 predictions ( 16.0%)\n",
      "   Level 11:  248 predictions (  7.3%)\n",
      "   Level 12:  689 predictions ( 20.1%)\n",
      "   Level 13:  143 predictions (  4.2%)\n",
      "   Level 14:  684 predictions ( 20.0%)\n",
      "   Level 15:   65 predictions (  1.9%)\n",
      "   Level 16:   32 predictions (  0.9%)\n",
      "\n",
      "🔢 Classification Prediction Statistics:\n",
      "   Mean predicted level: 10.481\n",
      "   Std predicted levels: 3.159\n",
      "   Min predicted level:  1\n",
      "   Max predicted level:  16\n",
      "\n",
      "📊 Probability Distribution Statistics:\n",
      "   Mean max probability: 0.753\n",
      "   Std max probability:  0.205\n",
      "   Min max probability:  0.161\n",
      "   Max max probability:  0.998\n",
      "\n",
      "✅ --- FINAL CLASSIFICATION PREDICTIONS SAVED --- ✅\n",
      "Detailed predictions with confidence: 'camelbert_msa_classification_detailed_predictions.csv'\n",
      "Standard submission file: 'camelbert_barec_blind_test_predictions_classification.csv'\n",
      "\n",
      "First 10 predictions with confidence scores:\n",
      "            ID  Predicted_Level  Raw_Prediction  Confidence\n",
      "0  10102950001                7               6    0.987703\n",
      "1  10102950002                8               7    0.695551\n",
      "2  10102950003               13              12    0.895435\n",
      "3  10102950004                7               6    0.394539\n",
      "4  10102950005                6               5    0.917502\n",
      "5  10102950006                8               7    0.983149\n",
      "6  10102950007                4               3    0.262061\n",
      "7  10102950008                6               5    0.702010\n",
      "8  10102950009                6               5    0.926296\n",
      "9  10102950010                6               5    0.919720\n",
      "\n",
      "Results summary saved to 'barec_results_with_blind_test_classification.json'\n",
      "🎯 Mean confidence score: 0.753\n",
      "📊 Mean predicted level: 10.481\n",
      "🇸🇦 XLM-RoBERTa Large Arabic QA classification predictions with confidence scores completed!\n",
      "📊 Cross Entropy Loss enables discrete classification for better readability assessment!\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Evaluate on the new Development Set (formerly test.csv) ---\n",
    "print(\"--- Evaluating XLM-RoBERTa Large Arabic QA Classification Model on Development Set (test.csv) ---\")\n",
    "dev_results = trainer.evaluate(eval_dataset=dev_dataset)\n",
    "\n",
    "# Extract metrics for printing\n",
    "dev_metrics_clean = {k.replace('eval_', ''): v for k, v in dev_results.items() if 'eval_' in k}\n",
    "print_metrics(dev_metrics_clean, \"XLM-RoBERTa Large Arabic QA Classification Development Set Results (using test.csv)\")\n",
    "\n",
    "# --- 2. Prepare the Blind Test Dataset for Prediction ---\n",
    "# We need a dataset class that handles text-only data (no labels)\n",
    "class BlindTestDataset(Dataset):\n",
    "    def __init__(self, sentences, tokenizer, max_length=128):\n",
    "        self.sentences = sentences\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = str(self.sentences[idx])\n",
    "        encoding = self.tokenizer(\n",
    "            sentence,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten()\n",
    "        }\n",
    "\n",
    "blind_dataset = BlindTestDataset(blind_test_sentences, tokenizer, MAX_LENGTH)\n",
    "print(f\"\\nBlind test dataset created with {len(blind_dataset)} samples.\")\n",
    "\n",
    "\n",
    "# --- 3. Generate Predictions on the Blind Test Set with Confidence Scores ---\n",
    "print(\"\\n--- Generating classification predictions for the blind test set ---\")\n",
    "# The trainer.predict method can handle datasets without labels\n",
    "blind_predictions = trainer.predict(blind_dataset)\n",
    "\n",
    "# For classification, the output is logits - convert to probabilities and get predicted classes\n",
    "logits = blind_predictions.predictions\n",
    "probabilities = torch.softmax(torch.tensor(logits), dim=1).numpy()\n",
    "\n",
    "# Get predicted class indices (0-18) and convert to readability levels (1-19)\n",
    "predicted_class_indices = np.argmax(logits, axis=1)\n",
    "predicted_labels = predicted_class_indices + 1  # Convert to 1-19 scale\n",
    "\n",
    "# Calculate confidence scores for classification\n",
    "# Use the maximum probability as confidence (how confident the model is in its prediction)\n",
    "confidence_scores = np.max(probabilities, axis=1)\n",
    "\n",
    "print(f\"Generated {len(predicted_labels)} classification predictions.\")\n",
    "\n",
    "# Analyze prediction confidence and distribution\n",
    "print(f\"\\n📊 XLM-RoBERTa Large Arabic QA Classification Prediction Confidence Analysis:\")\n",
    "print(f\"   Mean confidence: {confidence_scores.mean():.3f}\")\n",
    "print(f\"   Std confidence:  {confidence_scores.std():.3f}\")\n",
    "print(f\"   Min confidence:  {confidence_scores.min():.3f}\")\n",
    "print(f\"   Max confidence:  {confidence_scores.max():.3f}\")\n",
    "\n",
    "print(f\"\\n📈 Classification Prediction Distribution:\")\n",
    "unique_levels, counts = np.unique(predicted_labels, return_counts=True)\n",
    "for level, count in zip(unique_levels, counts):\n",
    "    percentage = (count / len(predicted_labels)) * 100\n",
    "    print(f\"   Level {level:2d}: {count:4d} predictions ({percentage:5.1f}%)\")\n",
    "\n",
    "# Show classification-specific statistics\n",
    "print(f\"\\n🔢 Classification Prediction Statistics:\")\n",
    "print(f\"   Mean predicted level: {predicted_labels.mean():.3f}\")\n",
    "print(f\"   Std predicted levels: {predicted_labels.std():.3f}\")\n",
    "print(f\"   Min predicted level:  {predicted_labels.min()}\")\n",
    "print(f\"   Max predicted level:  {predicted_labels.max()}\")\n",
    "\n",
    "# Show probability distribution statistics\n",
    "print(f\"\\n📊 Probability Distribution Statistics:\")\n",
    "print(f\"   Mean max probability: {confidence_scores.mean():.3f}\")\n",
    "print(f\"   Std max probability:  {confidence_scores.std():.3f}\")\n",
    "print(f\"   Min max probability:  {confidence_scores.min():.3f}\")\n",
    "print(f\"   Max max probability:  {confidence_scores.max():.3f}\")\n",
    "\n",
    "\n",
    "# --- 4. Save the Final Predictions with Confidence Scores ---\n",
    "# Create a dataframe with the required columns including confidence scores\n",
    "final_predictions_df = pd.DataFrame({\n",
    "    'ID': blind_test_df['ID'],\n",
    "    'Sentence': blind_test_sentences,\n",
    "    'Predicted_Level': predicted_labels,\n",
    "    'Raw_Prediction': predicted_class_indices,  # Include class indices (0-18)\n",
    "    'Confidence': confidence_scores\n",
    "})\n",
    "\n",
    "# Save detailed predictions for analysis\n",
    "detailed_filename = 'camelbert_msa_classification_detailed_predictions.csv'\n",
    "final_predictions_df.to_csv(detailed_filename, index=False, encoding='utf-8-sig')\n",
    "\n",
    "# Create standard submission file\n",
    "submission_df = pd.DataFrame({\n",
    "    'ID': blind_test_df['ID'],\n",
    "    'Predicted_Level': predicted_labels\n",
    "})\n",
    "\n",
    "output_filename = 'camelbert_barec_blind_test_predictions_classification.csv'\n",
    "submission_df.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"\\n✅ --- FINAL CLASSIFICATION PREDICTIONS SAVED --- ✅\")\n",
    "print(f\"Detailed predictions with confidence: '{detailed_filename}'\")\n",
    "print(f\"Standard submission file: '{output_filename}'\")\n",
    "print(\"\\nFirst 10 predictions with confidence scores:\")\n",
    "print(final_predictions_df[['ID', 'Predicted_Level', 'Raw_Prediction', 'Confidence']].head(10))\n",
    "\n",
    "# --- 5. Final Summary ---\n",
    "results_summary = {\n",
    "    'model_name': MODEL_NAME,\n",
    "    'model_type': 'XLM-RoBERTa Large Arabic QA Classification with Cross Entropy Loss',\n",
    "    'loss_function': 'Cross Entropy Loss',\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'dev_metrics': dev_metrics_clean,\n",
    "    'prediction_stats': {\n",
    "        'total_predictions': len(predicted_labels),\n",
    "        'mean_confidence': float(confidence_scores.mean()),\n",
    "        'mean_predicted_level': float(predicted_labels.mean()),\n",
    "        'std_predicted_level': float(predicted_labels.std()),\n",
    "        'prediction_distribution': {int(level): int(count) for level, count in zip(unique_levels, counts)},\n",
    "        'readability_range': {\n",
    "            'min_level': int(predicted_labels.min()),\n",
    "            'max_level': int(predicted_labels.max()),\n",
    "            'mean_level': float(predicted_labels.mean()),\n",
    "            'std_level': float(predicted_labels.std())\n",
    "        }\n",
    "    },\n",
    "    'dataset_sizes': {\n",
    "        'train': len(train_df),\n",
    "        'dev': len(dev_df),\n",
    "        'blind_test': len(blind_test_df)\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('barec_results_with_blind_test_classification.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(results_summary, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"\\nResults summary saved to 'barec_results_with_blind_test_classification.json'\")\n",
    "print(f\"🎯 Mean confidence score: {confidence_scores.mean():.3f}\")\n",
    "print(f\"📊 Mean predicted level: {predicted_labels.mean():.3f}\")\n",
    "print(\"🇸🇦 XLM-RoBERTa Large Arabic QA classification predictions with confidence scores completed!\")\n",
    "print(\"📊 Cross Entropy Loss enables discrete classification for better readability assessment!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b2166a",
   "metadata": {
    "id": "62b2166a"
   },
   "source": [
    "## 7. Push Model to Hugging Face Hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786b88b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Push Final Model to Hugging Face Hub ---\n",
    "print(\"🚀 Preparing to push XLM-RoBERTa Large Arabic QA classification model to Hugging Face Hub...\")\n",
    "\n",
    "# The trainer saves the best model in the output directory. We need to load it.\n",
    "final_model_path = './optimized_model' \n",
    "print(f\"Loading final XLM-RoBERTa Large Arabic QA classification model from: {final_model_path}\")\n",
    "\n",
    "# Load the best model and tokenizer\n",
    "# Note: We use the same AutoModelForSequenceClassification class\n",
    "model_to_push = AutoModelForSequenceClassification.from_pretrained(final_model_path)\n",
    "tokenizer_to_push = AutoTokenizer.from_pretrained(final_model_path)\n",
    "\n",
    "# Install huggingface_hub if not already installed\n",
    "try:\n",
    "    from huggingface_hub import HfApi, login\n",
    "    print(\"✅ huggingface_hub is available\")\n",
    "except ImportError:\n",
    "    print(\"📦 Installing huggingface_hub...\")\n",
    "    !pip install huggingface_hub\n",
    "    from huggingface_hub import HfApi, login\n",
    "    print(\"✅ huggingface_hub installed and imported\")\n",
    "\n",
    "# Login to Hugging Face with your token\n",
    "hf_token = \"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\" \n",
    "print(\"🔐 Logging in to Hugging Face...\")\n",
    "\n",
    "try:\n",
    "    login(token=hf_token, add_to_git_credential=True)\n",
    "    print(\"✅ Successfully logged in to Hugging Face!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Login failed: {e}\")\n",
    "\n",
    "# --- Model Repository Configuration ---\n",
    "# IMPORTANT: Please update these with your details\n",
    "username = \"MoT69420\"  # Your Hugging Face username\n",
    "model_repo_name = \"barec-camelbert-msa-classification-finetuned\"  # Updated repo name for XLM-RoBERTa Large Arabic QA classification model\n",
    "repo_id = f\"{username}/{model_repo_name}\"\n",
    "\n",
    "print(f\"\\nXLM-RoBERTa Large Arabic QA classification model will be pushed to: https://huggingface.co/{repo_id}\")\n",
    "\n",
    "# --- Push to Hub ---\n",
    "try:\n",
    "    print(f\"🔄 Pushing XLM-RoBERTa Large Arabic QA classification model to {repo_id}...\")\n",
    "    # The push_to_hub method handles creating the repo if it doesn't exist\n",
    "    model_to_push.push_to_hub(repo_id, private=True) # Set private=False for a public model\n",
    "    \n",
    "    print(f\"🔄 Pushing tokenizer to {repo_id}...\")\n",
    "    tokenizer_to_push.push_to_hub(repo_id, private=True) # Set private=False for a public model\n",
    "    \n",
    "    print(f\"\\n🎉 SUCCESS! XLM-RoBERTa Large Arabic QA classification model and tokenizer successfully pushed to {repo_id}\")\n",
    "    print(\"🇸🇦 Your Arabic-specialized classification model is now available on Hugging Face!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ ERROR pushing to Hugging Face: {e}\")\n",
    "    print(\"Please check the following:\")\n",
    "    print(\"1. Your username is correct.\")\n",
    "    print(\"2. Your Hugging Face token has 'write' permissions.\")\n",
    "    print(\"3. The repository doesn't have conflicting files.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "003e13f1e3b44f7fb7ba26757e630658": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "081c45ee0cf74cebb4e7492fb14556a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "09156589ff404455a821aa7a68be1a62": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0be998f74a474db190738216d69f0acb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c38c5efac824bf1b14651767b93abce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "10d50f9830624447856e59e78b7fb2b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f502c61dd6c468ab83e6a6ebb61621f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23abb601dedf432f8b2f9d364ee851e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2cff338ff5f0423eb06f1730ae8e2c76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2fba10200f8e425bb7e87e8556c6bc34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "33ccb32a03cb4e83bf4c45065d5fff4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0be998f74a474db190738216d69f0acb",
      "placeholder": "​",
      "style": "IPY_MODEL_2cff338ff5f0423eb06f1730ae8e2c76",
      "value": " 112/112 [00:00&lt;00:00, 5.68kB/s]"
     }
    },
    "36ca08b54833419e90b2054134268c5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d480fdb6bbe4d2c80c54b86e4d690a2",
      "placeholder": "​",
      "style": "IPY_MODEL_727d8c42596c40bd870816f5dfcca4f0",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "3ce6076aaedf463b8ef63062b9e81dec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d59c3414a9c453db798c20e097221c2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "3e063868493d44b18b5ba58f11355413": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45faf259c90245f3b261e29960df0380": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fe6ff805e4be4c04a01a1da7f76c37d3",
       "IPY_MODEL_6bede89609594ae98e6e6ef0be5156b3",
       "IPY_MODEL_33ccb32a03cb4e83bf4c45065d5fff4d"
      ],
      "layout": "IPY_MODEL_995f2037536c4c8395f58dd17631b707"
     }
    },
    "486e1db65e254a6582c4042fc2c59c1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_56a72d516e56418cb7de5daba4f14a79",
       "IPY_MODEL_e7b3635399e446838105a9296327ee08",
       "IPY_MODEL_d4653c75698a441894ea3493baf9a888"
      ],
      "layout": "IPY_MODEL_960f5003d3d34540b3a983c0de62c8df"
     }
    },
    "489a28aa17dd4a81adc1ad0a0a34b560": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "50d31da2c4014c5eb7c5a0bbd1a7a81a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "56a72d516e56418cb7de5daba4f14a79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3e063868493d44b18b5ba58f11355413",
      "placeholder": "​",
      "style": "IPY_MODEL_2fba10200f8e425bb7e87e8556c6bc34",
      "value": "config.json: 100%"
     }
    },
    "5e606f805f8f42b1b669c176de3f8df8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "659738becc9c47f6af45a4ad972d0b95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea1507678c17416b8a6f139d4be09c76",
      "placeholder": "​",
      "style": "IPY_MODEL_69380d6e06f849dba235c4dc48fecc92",
      "value": "vocab.txt: "
     }
    },
    "69380d6e06f849dba235c4dc48fecc92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6b37cf27b89e4f83ae631e47beadd986": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6bede89609594ae98e6e6ef0be5156b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_09156589ff404455a821aa7a68be1a62",
      "max": 112,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0c38c5efac824bf1b14651767b93abce",
      "value": 112
     }
    },
    "6df95b9811b74ddca25bc0f4257bc097": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_77b0e2a5a8564da0a2c90636bf16d359",
      "placeholder": "​",
      "style": "IPY_MODEL_6b37cf27b89e4f83ae631e47beadd986",
      "value": " 720k/? [00:00&lt;00:00, 11.8MB/s]"
     }
    },
    "727d8c42596c40bd870816f5dfcca4f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "77b0e2a5a8564da0a2c90636bf16d359": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78457311695943669e21049801e31e8d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "80395a9cb6f64658b27f1bf40e3b45bf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88f21c7af6ee4573a763361842a43fd2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9263e531606a44f3bd6b164a79c5f789": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_78457311695943669e21049801e31e8d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bf17000195434ddda79d600a63bedca1",
      "value": 1
     }
    },
    "9595ecc2490f49ea966aaeb50609e289": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d59c3414a9c453db798c20e097221c2",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_489a28aa17dd4a81adc1ad0a0a34b560",
      "value": 1
     }
    },
    "960f5003d3d34540b3a983c0de62c8df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "995f2037536c4c8395f58dd17631b707": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d480fdb6bbe4d2c80c54b86e4d690a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9dca3a79419345e1a5690589ddf50675": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_659738becc9c47f6af45a4ad972d0b95",
       "IPY_MODEL_9595ecc2490f49ea966aaeb50609e289",
       "IPY_MODEL_6df95b9811b74ddca25bc0f4257bc097"
      ],
      "layout": "IPY_MODEL_b4c4660bb38d49859254d11b1c1ca3c1"
     }
    },
    "a69a0952c5d748dda6c3b50c081095de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_80395a9cb6f64658b27f1bf40e3b45bf",
      "placeholder": "​",
      "style": "IPY_MODEL_fb0f09551f1642cfa0b65b583c9d1fe1",
      "value": " 611/611 [00:00&lt;00:00, 30.8kB/s]"
     }
    },
    "a7a9047f2bd240bca87bd1dcf23929b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_36ca08b54833419e90b2054134268c5a",
       "IPY_MODEL_b5186d0efa964427b42b2c8fd14d7e5e",
       "IPY_MODEL_a69a0952c5d748dda6c3b50c081095de"
      ],
      "layout": "IPY_MODEL_f70a9188d653421b95a2da6a8d6a3a87"
     }
    },
    "b4b47cc1be6b49bda4aca89ed81b32ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1f502c61dd6c468ab83e6a6ebb61621f",
      "placeholder": "​",
      "style": "IPY_MODEL_003e13f1e3b44f7fb7ba26757e630658",
      "value": "tokenizer.json: "
     }
    },
    "b4c4660bb38d49859254d11b1c1ca3c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b5186d0efa964427b42b2c8fd14d7e5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fcec51c756164065841cc067c7aa4b59",
      "max": 611,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bc2fbf43fede44e9a6be4523aec5a417",
      "value": 611
     }
    },
    "b825199285774f9383220106cf29207b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bbf2f4d9628149039ef6cb42fd9358c5",
      "placeholder": "​",
      "style": "IPY_MODEL_081c45ee0cf74cebb4e7492fb14556a2",
      "value": " 2.31M/? [00:00&lt;00:00, 41.1MB/s]"
     }
    },
    "bbf2f4d9628149039ef6cb42fd9358c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc2fbf43fede44e9a6be4523aec5a417": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bf17000195434ddda79d600a63bedca1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cd5880991d7343feb96cf7dcf54e5220": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4653c75698a441894ea3493baf9a888": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ce6076aaedf463b8ef63062b9e81dec",
      "placeholder": "​",
      "style": "IPY_MODEL_88f21c7af6ee4573a763361842a43fd2",
      "value": " 384/384 [00:00&lt;00:00, 13.6kB/s]"
     }
    },
    "d7ac15134fc8429083ce02fdccbd223d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b4b47cc1be6b49bda4aca89ed81b32ef",
       "IPY_MODEL_9263e531606a44f3bd6b164a79c5f789",
       "IPY_MODEL_b825199285774f9383220106cf29207b"
      ],
      "layout": "IPY_MODEL_10d50f9830624447856e59e78b7fb2b6"
     }
    },
    "e7b3635399e446838105a9296327ee08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e606f805f8f42b1b669c176de3f8df8",
      "max": 384,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_23abb601dedf432f8b2f9d364ee851e1",
      "value": 384
     }
    },
    "ea1507678c17416b8a6f139d4be09c76": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f70a9188d653421b95a2da6a8d6a3a87": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb0f09551f1642cfa0b65b583c9d1fe1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fcec51c756164065841cc067c7aa4b59": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe6ff805e4be4c04a01a1da7f76c37d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd5880991d7343feb96cf7dcf54e5220",
      "placeholder": "​",
      "style": "IPY_MODEL_50d31da2c4014c5eb7c5a0bbd1a7a81a",
      "value": "special_tokens_map.json: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
