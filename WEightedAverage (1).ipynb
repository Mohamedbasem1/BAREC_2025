{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0134ed44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the three prediction files...\n",
      "Columns in file 1: ['ID', 'Sentence', 'Predicted_Level', 'Confidence_Score', 'Model_Type', 'Prediction_Method']\n",
      "Columns in file 2: ['ID', 'Sentence', 'Predicted_Level', 'Raw_Prediction', 'Confidence_Score']\n",
      "Columns in file 3: ['ID', 'Sentence', 'Predicted_Level', 'Raw_Prediction', 'Confidence_Score']\n",
      "File 1 shape before cleaning: (3420, 4)\n",
      "File 1 shape after cleaning: (3420, 4)\n",
      "File 2 shape before cleaning: (3420, 4)\n",
      "File 2 shape after cleaning: (3420, 4)\n",
      "File 3 shape before cleaning: (3420, 4)\n",
      "File 3 shape after cleaning: (3420, 4)\n",
      "Total records loaded: 10260\n",
      "Unique sentence IDs: 3420\n",
      "\n",
      "Sample data:\n",
      "   Sentence_ID  Prediction  Confidence_Score      Model\n",
      "0  10102950001           7          0.538000  AraBERTv2\n",
      "1  10102950002           3          0.484714  AraBERTv2\n",
      "2  10102950003          12          0.228546  AraBERTv2\n",
      "3  10102950004          12          0.294010  AraBERTv2\n",
      "4  10102950005           5          0.374268  AraBERTv2\n",
      "5  10102950006           8          0.746147  AraBERTv2\n",
      "6  10102950007           7          0.580363  AraBERTv2\n",
      "7  10102950008           7          0.324463  AraBERTv2\n",
      "8  10102950009           6          0.310733  AraBERTv2\n",
      "9  10102950010           6          0.237147  AraBERTv2\n",
      "\n",
      "‚úÖ SUCCESS!\n",
      "üìÅ File saved as: Average Weighted Predictions3.csv\n",
      "üìä Total predictions: 3420\n",
      "üìã Columns: ['Sentence_ID', 'Prediction', 'Highest_Conf_Value']\n",
      "\n",
      "First 10 predictions:\n",
      "   Sentence_ID  Prediction  Highest_Conf_Value\n",
      "0  10102950001           7            0.973027\n",
      "1  10102950002           5            0.816176\n",
      "2  10102950003          11            0.835531\n",
      "3  10102950004           8            0.892899\n",
      "4  10102950005           6            0.914074\n",
      "5  10102950006           8            0.917652\n",
      "6  10102950007           6            0.969233\n",
      "7  10102950008           7            0.832274\n",
      "8  10102950009           6            0.803523\n",
      "9  10102950010           6            0.921243\n",
      "\n",
      "Last 10 predictions:\n",
      "      Sentence_ID  Prediction  Highest_Conf_Value\n",
      "3410  30500290026          14            0.992218\n",
      "3411  30500290027          14            0.720273\n",
      "3412  30500290029          14            0.924849\n",
      "3413  30500290030          14            0.896394\n",
      "3414  30500290031          14            0.855345\n",
      "3415  30500290032          14            0.896394\n",
      "3416  30500290033          14            0.932102\n",
      "3417  30500290034          14            0.709106\n",
      "3418  30500290035          15            0.692680\n",
      "3419  30500290036          14            0.848689\n",
      "\n",
      "Prediction statistics:\n",
      "Min prediction: 1\n",
      "Max prediction: 17\n",
      "Mean prediction: 10.74\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def create_weighted_average_predictions():\n",
    "    # Load the three CSV files\n",
    "    print(\"Loading the three prediction files...\")\n",
    "    \n",
    "    # File 1: arabertv2_ordinal_detailed_predictions.csv\n",
    "    df1 = pd.read_csv(r\"open_72,000_marbert_regression_weighted_detailed_predictions.csv\")\n",
    "    print(\"Columns in file 1:\", df1.columns.tolist())\n",
    "    # Rename columns to standardize\n",
    "    df1 = df1.rename(columns={'ID': 'Sentence_ID', 'Predicted_Level': 'Prediction'})\n",
    "    df1 = df1[['Sentence_ID', 'Prediction', 'Confidence_Score']].copy()\n",
    "    df1['Model'] = 'AraBERTv2'\n",
    "    \n",
    "    # File 2: araelectra_regression_detailed_predictions.csv  \n",
    "    df2 = pd.read_csv(r\"coral_arabertv2_OPEN_detailed_predictions (1).csv\")\n",
    "    print(\"Columns in file 2:\", df2.columns.tolist())\n",
    "    # Rename columns to standardize - this file has different column names\n",
    "    if 'Sentence ID' in df2.columns:\n",
    "        df2 = df2.rename(columns={'Sentence ID': 'Sentence_ID'})\n",
    "    if 'ID' in df2.columns:\n",
    "        df2 = df2.rename(columns={'ID': 'Sentence_ID'})\n",
    "    if 'Predicted_Level' in df2.columns:\n",
    "        df2 = df2.rename(columns={'Predicted_Level': 'Prediction'})\n",
    "    # Already has 'Prediction' column, no need to rename\n",
    "    df2 = df2[['Sentence_ID', 'Prediction', 'Confidence_Score']].copy()\n",
    "    df2['Model'] = 'AraELECTRA'\n",
    "    \n",
    "    # File 3: marabert_v2_regression_detailed_predictions.csv\n",
    "    df3 = pd.read_csv(r\"open_arabertv2_regression_weighted_detailed_predictions.csv\")\n",
    "    print(\"Columns in file 3:\", df3.columns.tolist())\n",
    "    # Rename columns to standardize - check if columns exist\n",
    "    if 'ID' in df3.columns:\n",
    "        df3 = df3.rename(columns={'ID': 'Sentence_ID'})\n",
    "    if 'Sentence ID' in df3.columns:\n",
    "        df3 = df3.rename(columns={'Sentence ID': 'Sentence_ID'})\n",
    "    if 'Predicted_Level' in df3.columns:\n",
    "        df3 = df3.rename(columns={'Predicted_Level': 'Prediction'})\n",
    "    \n",
    "    # Extract only the needed columns\n",
    "    df3 = df3[['Sentence_ID', 'Prediction', 'Confidence_Score']].copy()\n",
    "    df3['Model'] = 'MaraBERT'\n",
    "    \n",
    "    # Remove rows with NaN values\n",
    "    print(f\"File 1 shape before cleaning: {df1.shape}\")\n",
    "    df1 = df1.dropna(subset=['Sentence_ID', 'Prediction', 'Confidence_Score'])\n",
    "    print(f\"File 1 shape after cleaning: {df1.shape}\")\n",
    "    \n",
    "    print(f\"File 2 shape before cleaning: {df2.shape}\")\n",
    "    df2 = df2.dropna(subset=['Sentence_ID', 'Prediction', 'Confidence_Score'])\n",
    "    print(f\"File 2 shape after cleaning: {df2.shape}\")\n",
    "    \n",
    "    print(f\"File 3 shape before cleaning: {df3.shape}\")\n",
    "    df3 = df3.dropna(subset=['Sentence_ID', 'Prediction', 'Confidence_Score'])\n",
    "    print(f\"File 3 shape after cleaning: {df3.shape}\")\n",
    "    \n",
    "    # Combine all dataframes\n",
    "    all_predictions = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "    \n",
    "    print(f\"Total records loaded: {len(all_predictions)}\")\n",
    "    print(f\"Unique sentence IDs: {all_predictions['Sentence_ID'].nunique()}\")\n",
    "    print(\"\\nSample data:\")\n",
    "    print(all_predictions.head(10))\n",
    "    \n",
    "    # Calculate weighted average for each sentence ID\n",
    "    weighted_results = []\n",
    "    \n",
    "    # Get unique sentence IDs and remove any NaN values\n",
    "    unique_sentence_ids = all_predictions['Sentence_ID'].dropna().unique()\n",
    "    \n",
    "    for sentence_id in unique_sentence_ids:\n",
    "        # Skip if sentence_id is NaN or empty\n",
    "        if pd.isna(sentence_id):\n",
    "            continue\n",
    "            \n",
    "        # Get all predictions for this sentence\n",
    "        sentence_data = all_predictions[all_predictions['Sentence_ID'] == sentence_id]\n",
    "        \n",
    "        if len(sentence_data) < 2:\n",
    "            print(f\"Warning: Sentence {sentence_id} has only {len(sentence_data)} predictions\")\n",
    "            continue\n",
    "            \n",
    "        # Extract predictions and confidences\n",
    "        predictions = sentence_data['Prediction'].values\n",
    "        confidences = sentence_data['Confidence_Score'].values\n",
    "        models = sentence_data['Model'].values\n",
    "        \n",
    "        # Remove any NaN values from predictions and confidences\n",
    "        valid_indices = ~(pd.isna(predictions) | pd.isna(confidences))\n",
    "        predictions = predictions[valid_indices]\n",
    "        confidences = confidences[valid_indices]\n",
    "        models = models[valid_indices]\n",
    "        \n",
    "        if len(predictions) == 0:\n",
    "            print(f\"Warning: No valid predictions for sentence {sentence_id}\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate weighted average: (pred1*conf1 + pred2*conf2 + pred3*conf3) / (conf1 + conf2 + conf3)\n",
    "        weighted_sum = np.sum(predictions * confidences)\n",
    "        confidence_sum = np.sum(confidences)\n",
    "        \n",
    "        if confidence_sum > 0:\n",
    "            weighted_avg = weighted_sum / confidence_sum\n",
    "            # Calculate weighted confidence (average of confidences weighted by their own values)\n",
    "            weighted_confidence = confidence_sum / len(confidences)\n",
    "            # Round to nearest integer since predictions should be integers\n",
    "            final_prediction = round(weighted_avg)\n",
    "        else:\n",
    "            # Fallback to simple average if confidence sum is 0\n",
    "            final_prediction = round(np.mean(predictions))\n",
    "            weighted_confidence = np.mean(confidences) if len(confidences) > 0 else 0.0\n",
    "        \n",
    "        # Find the model with highest confidence for this sentence\n",
    "        max_conf_idx = np.argmax(confidences)\n",
    "        highest_conf_model = models[max_conf_idx]\n",
    "        highest_conf_value = confidences[max_conf_idx]\n",
    "        highest_conf_prediction = predictions[max_conf_idx]\n",
    "        \n",
    "        weighted_results.append({\n",
    "            'Sentence_ID': sentence_id,\n",
    "            'Prediction': final_prediction,\n",
    "            'Highest_Conf_Value': highest_conf_value,\n",
    "        })\n",
    "    \n",
    "    # Create final dataframe\n",
    "    result_df = pd.DataFrame(weighted_results)\n",
    "    \n",
    "    # Check if we have any results\n",
    "    if len(result_df) == 0:\n",
    "        print(\"‚ùå ERROR: No valid results generated!\")\n",
    "        return None\n",
    "    \n",
    "    # Sort by Sentence_ID to ensure proper order\n",
    "    result_df = result_df.sort_values('Sentence_ID')\n",
    "    \n",
    "    # Convert Sentence_ID to string to match original format if needed\n",
    "    result_df['Sentence_ID'] = result_df['Sentence_ID'].astype(str)\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_file = \"Average Weighted Predictions3.csv\"\n",
    "    result_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"\\n‚úÖ SUCCESS!\")\n",
    "    print(f\"üìÅ File saved as: {output_file}\")\n",
    "    print(f\"üìä Total predictions: {len(result_df)}\")\n",
    "    print(f\"üìã Columns: {result_df.columns.tolist()}\")\n",
    "    print(f\"\\nFirst 10 predictions:\")\n",
    "    print(result_df.head(10))\n",
    "    print(f\"\\nLast 10 predictions:\")\n",
    "    print(result_df.tail(10))\n",
    "    \n",
    "    # Show some statistics\n",
    "    print(f\"\\nPrediction statistics:\")\n",
    "    print(f\"Min prediction: {result_df['Prediction'].min()}\")\n",
    "    print(f\"Max prediction: {result_df['Prediction'].max()}\")\n",
    "    print(f\"Mean prediction: {result_df['Prediction'].mean():.2f}\")\n",
    "    \n",
    "\n",
    "\n",
    "# Run the function\n",
    "result = create_weighted_average_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3900b2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the five prediction files...\n",
      "Columns in file 1: ['ID', 'Sentence', 'Predicted_Level', 'Raw_Prediction', 'Confidence_Score']\n",
      "Columns in file 2: ['ID', 'Sentence', 'Predicted_Level', 'Raw_Prediction', 'Confidence_Score']\n",
      "Columns in file 3: ['ID', 'Sentence', 'Predicted_Level', 'Raw_Prediction', 'Confidence_Score']\n",
      "Columns in file 4: ['ID', 'Sentence', 'Predicted_Level', 'Confidence_Score', 'Model_Type', 'Prediction_Method']\n",
      "Columns in file 5: ['ID', 'Sentence', 'Predicted_Level', 'Raw_Prediction', 'Confidence_Score']\n",
      "File 1 shape before cleaning: (3420, 4)\n",
      "File 1 shape after cleaning: (3420, 4)\n",
      "File 2 shape before cleaning: (3420, 4)\n",
      "File 2 shape after cleaning: (3420, 4)\n",
      "File 3 shape before cleaning: (3420, 4)\n",
      "File 3 shape after cleaning: (3420, 4)\n",
      "File 4 shape before cleaning: (3420, 4)\n",
      "File 4 shape after cleaning: (3420, 4)\n",
      "File 5 shape before cleaning: (3420, 4)\n",
      "File 5 shape after cleaning: (3420, 4)\n",
      "Total records loaded: 17100\n",
      "Unique sentence IDs: 3420\n",
      "\n",
      "Sample data:\n",
      "   Sentence_ID  Prediction  Confidence_Score      Model\n",
      "0  10102950001           7          0.980658  AraBERTv2\n",
      "1  10102950002           2          0.976835  AraBERTv2\n",
      "2  10102950003           9          0.816176  AraBERTv2\n",
      "3  10102950004          10          0.720273  AraBERTv2\n",
      "4  10102950005           5          0.943090  AraBERTv2\n",
      "5  10102950006           7          0.625784  AraBERTv2\n",
      "6  10102950007           6          0.643131  AraBERTv2\n",
      "7  10102950008           7          0.885951  AraBERTv2\n",
      "8  10102950009           6          0.965455  AraBERTv2\n",
      "9  10102950010           5          0.613680  AraBERTv2\n",
      "\n",
      "‚úÖ SUCCESS!\n",
      "üìÅ File saved as: Average Weighted Predictions_5models.csv\n",
      "üìä Total predictions: 3420\n",
      "üìã Columns: ['Sentence_ID', 'Prediction', 'Highest_Conf_Value']\n",
      "\n",
      "First 10 predictions:\n",
      "   Sentence_ID  Prediction  Highest_Conf_Value\n",
      "0  10102950001           7            0.982484\n",
      "1  10102950002           4            0.976835\n",
      "2  10102950003          11            0.906564\n",
      "3  10102950004          10            0.822578\n",
      "4  10102950005           6            0.943090\n",
      "5  10102950006           8            0.917652\n",
      "6  10102950007           6            0.969233\n",
      "7  10102950008           7            0.885951\n",
      "8  10102950009           6            0.965455\n",
      "9  10102950010           6            0.921243\n",
      "\n",
      "Last 10 predictions:\n",
      "      Sentence_ID  Prediction  Highest_Conf_Value\n",
      "3410  30500290026          14            0.992218\n",
      "3411  30500290027          13            0.841090\n",
      "3412  30500290029          13            0.917652\n",
      "3413  30500290030          14            0.885856\n",
      "3414  30500290031          14            0.939413\n",
      "3415  30500290032          14            0.875068\n",
      "3416  30500290033          14            0.932102\n",
      "3417  30500290034          14            0.816176\n",
      "3418  30500290035          14            0.861005\n",
      "3419  30500290036          14            0.928231\n",
      "\n",
      "Prediction statistics:\n",
      "Min prediction: 1\n",
      "Max prediction: 16\n",
      "Mean prediction: 10.60\n",
      "\n",
      "Model distribution in data:\n",
      "Model\n",
      "AraBERTv2     3420\n",
      "AraELECTRA    3420\n",
      "MaraBERT      3420\n",
      "Model4        3420\n",
      "Model5        3420\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def create_weighted_average_predictions():\n",
    "    # Load the five CSV files\n",
    "    print(\"Loading the five prediction files...\")\n",
    "    \n",
    "    # File 1: arabertv2_ordinal_detailed_predictions.csv\n",
    "    df1 = pd.read_csv(r\"arabertv2_regression_weighted_detailed_predictions.csv\")\n",
    "    print(\"Columns in file 1:\", df1.columns.tolist())\n",
    "    # Rename columns to standardize\n",
    "    df1 = df1.rename(columns={'ID': 'Sentence_ID', 'Predicted_Level': 'Prediction'})\n",
    "    df1 = df1[['Sentence_ID', 'Prediction', 'Confidence_Score']].copy()\n",
    "    df1['Model'] = 'AraBERTv2'\n",
    "    \n",
    "    # File 2: araelectra_regression_detailed_predictions.csv  \n",
    "    df2 = pd.read_csv(r\"Samer_coral_arabertv2_d3tok_detailed_predictions.csv\")\n",
    "    print(\"Columns in file 2:\", df2.columns.tolist())\n",
    "    # Rename columns to standardize - this file has different column names\n",
    "    if 'Sentence ID' in df2.columns:\n",
    "        df2 = df2.rename(columns={'Sentence ID': 'Sentence_ID'})\n",
    "    if 'ID' in df2.columns:\n",
    "        df2 = df2.rename(columns={'ID': 'Sentence_ID'})\n",
    "    if 'Predicted_Level' in df2.columns:\n",
    "        df2 = df2.rename(columns={'Predicted_Level': 'Prediction'})\n",
    "    # Already has 'Prediction' column, no need to rename\n",
    "    df2 = df2[['Sentence_ID', 'Prediction', 'Confidence_Score']].copy()\n",
    "    df2['Model'] = 'AraELECTRA'\n",
    "    \n",
    "    # File 3: marabert_v2_regression_detailed_predictions.csv\n",
    "    df3 = pd.read_csv(r\"coral_arabertv2_d3tok_detailed_predictions.csv\")\n",
    "    print(\"Columns in file 3:\", df3.columns.tolist())\n",
    "    # Rename columns to standardize - check if columns exist\n",
    "    if 'ID' in df3.columns:\n",
    "        df3 = df3.rename(columns={'ID': 'Sentence_ID'})\n",
    "    if 'Sentence ID' in df3.columns:\n",
    "        df3 = df3.rename(columns={'Sentence ID': 'Sentence_ID'})\n",
    "    if 'Predicted_Level' in df3.columns:\n",
    "        df3 = df3.rename(columns={'Predicted_Level': 'Prediction'})\n",
    "    \n",
    "    # Extract only the needed columns\n",
    "    df3 = df3[['Sentence_ID', 'Prediction', 'Confidence_Score']].copy()\n",
    "    df3['Model'] = 'MaraBERT'\n",
    "    \n",
    "\n",
    "    # arabertv2_classification_detailed_predictions (1)\n",
    "    # File 4: Add your fourth file here\n",
    "    df4 = pd.read_csv(r\"araelctra_regression_weighted_detailed_predictions.csv\")  # Replace with your actual filename\n",
    "    print(\"Columns in file 4:\", df4.columns.tolist())\n",
    "    # Rename columns to standardize - check if columns exist\n",
    "    if 'ID' in df4.columns:\n",
    "        df4 = df4.rename(columns={'ID': 'Sentence_ID'})\n",
    "    if 'Sentence ID' in df4.columns:\n",
    "        df4 = df4.rename(columns={'Sentence ID': 'Sentence_ID'})\n",
    "    if 'Predicted_Level' in df4.columns:\n",
    "        df4 = df4.rename(columns={'Predicted_Level': 'Prediction'})\n",
    "    \n",
    "    # Extract only the needed columns\n",
    "    df4 = df4[['Sentence_ID', 'Prediction', 'Confidence_Score']].copy()\n",
    "    df4['Model'] = 'Model4'  # Replace with your actual model name\n",
    "    \n",
    "    # File 5: Add your fifth file here\n",
    "    df5 = pd.read_csv(r\"Samer_camelbert_msa_classification_detailed_predictions.csv\")  # Replace with your actual filename\n",
    "    print(\"Columns in file 5:\", df5.columns.tolist())\n",
    "    # Rename columns to standardize - check if columns exist\n",
    "    if 'ID' in df5.columns:\n",
    "        df5 = df5.rename(columns={'ID': 'Sentence_ID'})\n",
    "    if 'Sentence ID' in df5.columns:\n",
    "        df5 = df5.rename(columns={'Sentence ID': 'Sentence_ID'})\n",
    "    if 'Predicted_Level' in df5.columns:\n",
    "        df5 = df5.rename(columns={'Predicted_Level': 'Prediction'})\n",
    "    \n",
    "    # Extract only the needed columns\n",
    "    df5 = df5[['Sentence_ID', 'Prediction', 'Confidence_Score']].copy()\n",
    "    df5['Model'] = 'Model5'  # Replace with your actual model name\n",
    "    \n",
    "    # Remove rows with NaN values for all files\n",
    "    print(f\"File 1 shape before cleaning: {df1.shape}\")\n",
    "    df1 = df1.dropna(subset=['Sentence_ID', 'Prediction', 'Confidence_Score'])\n",
    "    print(f\"File 1 shape after cleaning: {df1.shape}\")\n",
    "    \n",
    "    print(f\"File 2 shape before cleaning: {df2.shape}\")\n",
    "    df2 = df2.dropna(subset=['Sentence_ID', 'Prediction', 'Confidence_Score'])\n",
    "    print(f\"File 2 shape after cleaning: {df2.shape}\")\n",
    "    \n",
    "    print(f\"File 3 shape before cleaning: {df3.shape}\")\n",
    "    df3 = df3.dropna(subset=['Sentence_ID', 'Prediction', 'Confidence_Score'])\n",
    "    print(f\"File 3 shape after cleaning: {df3.shape}\")\n",
    "    \n",
    "    print(f\"File 4 shape before cleaning: {df4.shape}\")\n",
    "    df4 = df4.dropna(subset=['Sentence_ID', 'Prediction', 'Confidence_Score'])\n",
    "    print(f\"File 4 shape after cleaning: {df4.shape}\")\n",
    "    \n",
    "    print(f\"File 5 shape before cleaning: {df5.shape}\")\n",
    "    df5 = df5.dropna(subset=['Sentence_ID', 'Prediction', 'Confidence_Score'])\n",
    "    print(f\"File 5 shape after cleaning: {df5.shape}\")\n",
    "    \n",
    "    # Combine all dataframes (now including df4 and df5)\n",
    "    all_predictions = pd.concat([df1, df2, df3, df4, df5], ignore_index=True)\n",
    "    \n",
    "    print(f\"Total records loaded: {len(all_predictions)}\")\n",
    "    print(f\"Unique sentence IDs: {all_predictions['Sentence_ID'].nunique()}\")\n",
    "    print(\"\\nSample data:\")\n",
    "    print(all_predictions.head(10))\n",
    "    \n",
    "    # Calculate weighted average for each sentence ID\n",
    "    weighted_results = []\n",
    "    \n",
    "    # Get unique sentence IDs and remove any NaN values\n",
    "    unique_sentence_ids = all_predictions['Sentence_ID'].dropna().unique()\n",
    "    \n",
    "    for sentence_id in unique_sentence_ids:\n",
    "        # Skip if sentence_id is NaN or empty\n",
    "        if pd.isna(sentence_id):\n",
    "            continue\n",
    "            \n",
    "        # Get all predictions for this sentence\n",
    "        sentence_data = all_predictions[all_predictions['Sentence_ID'] == sentence_id]\n",
    "        \n",
    "        if len(sentence_data) < 2:\n",
    "            print(f\"Warning: Sentence {sentence_id} has only {len(sentence_data)} predictions\")\n",
    "            continue\n",
    "            \n",
    "        # Extract predictions and confidences\n",
    "        predictions = sentence_data['Prediction'].values\n",
    "        confidences = sentence_data['Confidence_Score'].values\n",
    "        models = sentence_data['Model'].values\n",
    "        \n",
    "        # Remove any NaN values from predictions and confidences\n",
    "        valid_indices = ~(pd.isna(predictions) | pd.isna(confidences))\n",
    "        predictions = predictions[valid_indices]\n",
    "        confidences = confidences[valid_indices]\n",
    "        models = models[valid_indices]\n",
    "        \n",
    "        if len(predictions) == 0:\n",
    "            print(f\"Warning: No valid predictions for sentence {sentence_id}\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate weighted average: (pred1*conf1 + pred2*conf2 + ... + pred5*conf5) / (conf1 + conf2 + ... + conf5)\n",
    "        weighted_sum = np.sum(predictions * confidences)\n",
    "        confidence_sum = np.sum(confidences)\n",
    "        \n",
    "        if confidence_sum > 0:\n",
    "            weighted_avg = weighted_sum / confidence_sum\n",
    "            # Calculate weighted confidence (average of confidences weighted by their own values)\n",
    "            weighted_confidence = confidence_sum / len(confidences)\n",
    "            # Round to nearest integer since predictions should be integers\n",
    "            final_prediction = round(weighted_avg)\n",
    "        else:\n",
    "            # Fallback to simple average if confidence sum is 0\n",
    "            final_prediction = round(np.mean(predictions))\n",
    "            weighted_confidence = np.mean(confidences) if len(confidences) > 0 else 0.0\n",
    "        \n",
    "        # Find the model with highest confidence for this sentence\n",
    "        max_conf_idx = np.argmax(confidences)\n",
    "        highest_conf_model = models[max_conf_idx]\n",
    "        highest_conf_value = confidences[max_conf_idx]\n",
    "        highest_conf_prediction = predictions[max_conf_idx]\n",
    "        \n",
    "        weighted_results.append({\n",
    "            'Sentence_ID': sentence_id,\n",
    "            'Prediction': final_prediction,\n",
    "            'Highest_Conf_Value': highest_conf_value,\n",
    "        })\n",
    "    \n",
    "    # Create final dataframe\n",
    "    result_df = pd.DataFrame(weighted_results)\n",
    "    \n",
    "    # Check if we have any results\n",
    "    if len(result_df) == 0:\n",
    "        print(\"‚ùå ERROR: No valid results generated!\")\n",
    "        return None\n",
    "    \n",
    "    # Sort by Sentence_ID to ensure proper order\n",
    "    result_df = result_df.sort_values('Sentence_ID')\n",
    "    \n",
    "    # Convert Sentence_ID to string to match original format if needed\n",
    "    result_df['Sentence_ID'] = result_df['Sentence_ID'].astype(str)\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_file = \"Average Weighted Predictions_5models.csv\"\n",
    "    result_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"\\n‚úÖ SUCCESS!\")\n",
    "    print(f\"üìÅ File saved as: {output_file}\")\n",
    "    print(f\"üìä Total predictions: {len(result_df)}\")\n",
    "    print(f\"üìã Columns: {result_df.columns.tolist()}\")\n",
    "    print(f\"\\nFirst 10 predictions:\")\n",
    "    print(result_df.head(10))\n",
    "    print(f\"\\nLast 10 predictions:\")\n",
    "    print(result_df.tail(10))\n",
    "    \n",
    "    # Show some statistics\n",
    "    print(f\"\\nPrediction statistics:\")\n",
    "    print(f\"Min prediction: {result_df['Prediction'].min()}\")\n",
    "    print(f\"Max prediction: {result_df['Prediction'].max()}\")\n",
    "    print(f\"Mean prediction: {result_df['Prediction'].mean():.2f}\")\n",
    "    \n",
    "    # Show model distribution\n",
    "    print(f\"\\nModel distribution in data:\")\n",
    "    print(all_predictions['Model'].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "# Run the function\n",
    "result = create_weighted_average_predictions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7958c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the four prediction files...\n",
      "Columns in file 1: ['ID', 'Sentence', 'Predicted_Level', 'Raw_Prediction', 'Confidence_Score']\n",
      "Columns in file 2: ['ID', 'Sentence', 'Predicted_Level', 'Confidence_Score', 'Model_Type', 'Prediction_Method']\n",
      "Columns in file 3: ['ID', 'Sentence', 'Predicted_Level', 'Raw_Prediction', 'Confidence_Score']\n",
      "Columns in file 4: ['ID', 'Sentence', 'Predicted_Level', 'Raw_Prediction', 'Confidence_Score']\n",
      "File 1 shape before cleaning: (3420, 4)\n",
      "File 1 shape after cleaning: (3420, 4)\n",
      "File 2 shape before cleaning: (3420, 4)\n",
      "File 2 shape after cleaning: (3420, 4)\n",
      "File 3 shape before cleaning: (3420, 4)\n",
      "File 3 shape after cleaning: (3420, 4)\n",
      "File 4 shape before cleaning: (3420, 4)\n",
      "File 4 shape after cleaning: (3420, 4)\n",
      "Total records loaded: 13680\n",
      "Unique sentence IDs: 3420\n",
      "\n",
      "Sample data:\n",
      "   Sentence_ID  Prediction  Confidence_Score      Model\n",
      "0  10102950001           7          0.988350  AraBERTv2\n",
      "1  10102950002           5          0.760760  AraBERTv2\n",
      "2  10102950003          11          0.635639  AraBERTv2\n",
      "3  10102950004           9          0.731616  AraBERTv2\n",
      "4  10102950005           9          0.946781  AraBERTv2\n",
      "5  10102950006           8          0.835531  AraBERTv2\n",
      "6  10102950007           5          0.852011  AraBERTv2\n",
      "7  10102950008           6          0.865428  AraBERTv2\n",
      "8  10102950009           6          0.784909  AraBERTv2\n",
      "9  10102950010           7          0.666144  AraBERTv2\n",
      "\n",
      "‚úÖ SUCCESS!\n",
      "üìÅ File saved as: Average Weighted Predictions_4models.csv\n",
      "üìä Total predictions: 3420\n",
      "üìã Columns: ['Sentence ID', 'Prediction', 'Highest_Conf_Value']\n",
      "\n",
      "First 10 predictions:\n",
      "   Sentence ID  Prediction  Highest_Conf_Value\n",
      "0  10102950001           7            0.988350\n",
      "1  10102950002           4            0.760760\n",
      "2  10102950003          11            0.992218\n",
      "3  10102950004           9            0.906961\n",
      "4  10102950005           8            0.946781\n",
      "5  10102950006           8            0.935398\n",
      "6  10102950007           4            0.928469\n",
      "7  10102950008           6            0.865428\n",
      "8  10102950009           6            0.858693\n",
      "9  10102950010           6            0.950487\n",
      "\n",
      "Last 10 predictions:\n",
      "      Sentence ID  Prediction  Highest_Conf_Value\n",
      "3410  30500290026          15            0.655816\n",
      "3411  30500290027          13            0.917652\n",
      "3412  30500290029          13            0.910510\n",
      "3413  30500290030          14            0.760760\n",
      "3414  30500290031          14            0.992218\n",
      "3415  30500290032          15            0.862054\n",
      "3416  30500290033          14            0.946781\n",
      "3417  30500290034          15            0.992218\n",
      "3418  30500290035          14            0.650712\n",
      "3419  30500290036          14            0.855345\n",
      "\n",
      "Prediction statistics:\n",
      "Min prediction: 1\n",
      "Max prediction: 17\n",
      "Mean prediction: 10.65\n",
      "\n",
      "Model distribution in data:\n",
      "Model\n",
      "AraBERTv2     3420\n",
      "AraELECTRA    3420\n",
      "MaraBERT      3420\n",
      "MaraBERTv2    3420\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def create_weighted_average_predictions():\n",
    "    # Load the four CSV files\n",
    "    print(\"Loading the four prediction files...\")\n",
    "    \n",
    "    \n",
    "    # File 1: arabertv2_ordinal_detailed_predictions.csv\n",
    "    df1 = pd.read_csv(r\"open_72,000_marbert_regression_weighted_detailed_predictions.csv\")\n",
    "    print(\"Columns in file 1:\", df1.columns.tolist())\n",
    "    # Rename columns to standardize\n",
    "    df1 = df1.rename(columns={'ID': 'Sentence_ID', 'Predicted_Level': 'Prediction'})\n",
    "    df1 = df1[['Sentence_ID', 'Prediction', 'Confidence_Score']].copy()\n",
    "    df1['Model'] = 'AraBERTv2'\n",
    "    \n",
    "    # File 2: araelectra_regression_detailed_predictions.csv  \n",
    "    df2 = pd.read_csv(r\"coral_arabertv2_OPEN_detailed_predictions (1).csv\")\n",
    "    print(\"Columns in file 2:\", df2.columns.tolist())\n",
    "    # Rename columns to standardize - this file has different column names\n",
    "    if 'Sentence ID' in df2.columns:\n",
    "        df2 = df2.rename(columns={'Sentence ID': 'Sentence_ID'})\n",
    "    if 'ID' in df2.columns:\n",
    "        df2 = df2.rename(columns={'ID': 'Sentence_ID'})\n",
    "    if 'Predicted_Level' in df2.columns:\n",
    "        df2 = df2.rename(columns={'Predicted_Level': 'Prediction'})\n",
    "    # Already has 'Prediction' column, no need to rename\n",
    "    df2 = df2[['Sentence_ID', 'Prediction', 'Confidence_Score']].copy()\n",
    "    df2['Model'] = 'AraELECTRA'\n",
    "    \n",
    "    # File 3: marabert_v2_regression_detailed_predictions.csv\n",
    "    df3 = pd.read_csv(r\"open_arabertv2_regression_weighted_detailed_predictions.csv\")\n",
    "    print(\"Columns in file 3:\", df3.columns.tolist())\n",
    "    # Rename columns to standardize - check if columns exist\n",
    "    if 'ID' in df3.columns:\n",
    "        df3 = df3.rename(columns={'ID': 'Sentence_ID'})\n",
    "    if 'Sentence ID' in df3.columns:\n",
    "        df3 = df3.rename(columns={'Sentence ID': 'Sentence_ID'})\n",
    "    if 'Predicted_Level' in df3.columns:\n",
    "        df3 = df3.rename(columns={'Predicted_Level': 'Prediction'})\n",
    "    \n",
    "    # Extract only the needed columns\n",
    "    df3 = df3[['Sentence_ID', 'Prediction', 'Confidence_Score']].copy()\n",
    "    df3['Model'] = 'MaraBERT'\n",
    "    \n",
    "    # File 4: marbertv2_classification_detailed_predictions.csv\n",
    "    df4 = pd.read_csv(r\"72,000_araelctra_regression_weighted_detailed_predictions (1).csv\")\n",
    "    print(\"Columns in file 4:\", df4.columns.tolist())\n",
    "    # Rename columns to standardize - check if columns exist\n",
    "    if 'ID' in df4.columns:\n",
    "        df4 = df4.rename(columns={'ID': 'Sentence_ID'})\n",
    "    if 'Sentence ID' in df4.columns:\n",
    "        df4 = df4.rename(columns={'Sentence ID': 'Sentence_ID'})\n",
    "    if 'Predicted_Level' in df4.columns:\n",
    "        df4 = df4.rename(columns={'Predicted_Level': 'Prediction'})\n",
    "    \n",
    "    # Extract only the needed columns\n",
    "    df4 = df4[['Sentence_ID', 'Prediction', 'Confidence_Score']].copy()\n",
    "    df4['Model'] = 'MaraBERTv2'\n",
    "    \n",
    "    # Remove rows with NaN values for all files\n",
    "    print(f\"File 1 shape before cleaning: {df1.shape}\")\n",
    "    df1 = df1.dropna(subset=['Sentence_ID', 'Prediction', 'Confidence_Score'])\n",
    "    print(f\"File 1 shape after cleaning: {df1.shape}\")\n",
    "    \n",
    "    print(f\"File 2 shape before cleaning: {df2.shape}\")\n",
    "    df2 = df2.dropna(subset=['Sentence_ID', 'Prediction', 'Confidence_Score'])\n",
    "    print(f\"File 2 shape after cleaning: {df2.shape}\")\n",
    "    \n",
    "    print(f\"File 3 shape before cleaning: {df3.shape}\")\n",
    "    df3 = df3.dropna(subset=['Sentence_ID', 'Prediction', 'Confidence_Score'])\n",
    "    print(f\"File 3 shape after cleaning: {df3.shape}\")\n",
    "    \n",
    "    print(f\"File 4 shape before cleaning: {df4.shape}\")\n",
    "    df4 = df4.dropna(subset=['Sentence_ID', 'Prediction', 'Confidence_Score'])\n",
    "    print(f\"File 4 shape after cleaning: {df4.shape}\")\n",
    "    \n",
    "    # Combine all dataframes (now including df1, df2, df3, df4)\n",
    "    all_predictions = pd.concat([df1, df2, df3, df4], ignore_index=True)\n",
    "    \n",
    "    print(f\"Total records loaded: {len(all_predictions)}\")\n",
    "    print(f\"Unique sentence IDs: {all_predictions['Sentence_ID'].nunique()}\")\n",
    "    print(\"\\nSample data:\")\n",
    "    print(all_predictions.head(10))\n",
    "    \n",
    "    # Calculate weighted average for each sentence ID\n",
    "    weighted_results = []\n",
    "    \n",
    "    # Get unique sentence IDs and remove any NaN values\n",
    "    unique_sentence_ids = all_predictions['Sentence_ID'].dropna().unique()\n",
    "    \n",
    "    for sentence_id in unique_sentence_ids:\n",
    "        # Skip if sentence_id is NaN or empty\n",
    "        if pd.isna(sentence_id):\n",
    "            continue\n",
    "            \n",
    "        # Get all predictions for this sentence\n",
    "        sentence_data = all_predictions[all_predictions['Sentence_ID'] == sentence_id]\n",
    "        \n",
    "        if len(sentence_data) < 2:\n",
    "            print(f\"Warning: Sentence {sentence_id} has only {len(sentence_data)} predictions\")\n",
    "            continue\n",
    "            \n",
    "        # Extract predictions and confidences\n",
    "        predictions = sentence_data['Prediction'].values\n",
    "        confidences = sentence_data['Confidence_Score'].values\n",
    "        models = sentence_data['Model'].values\n",
    "        \n",
    "        # Remove any NaN values from predictions and confidences\n",
    "        valid_indices = ~(pd.isna(predictions) | pd.isna(confidences))\n",
    "        predictions = predictions[valid_indices]\n",
    "        confidences = confidences[valid_indices]\n",
    "        models = models[valid_indices]\n",
    "        \n",
    "        if len(predictions) == 0:\n",
    "            print(f\"Warning: No valid predictions for sentence {sentence_id}\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate weighted average: (pred1*conf1 + pred2*conf2 + pred3*conf3 + pred4*conf4) / (conf1 + conf2 + conf3 + conf4)\n",
    "        weighted_sum = np.sum(predictions * confidences)\n",
    "        confidence_sum = np.sum(confidences)\n",
    "        \n",
    "        if confidence_sum > 0:\n",
    "            weighted_avg = weighted_sum / confidence_sum\n",
    "            # Calculate weighted confidence (average of confidences weighted by their own values)\n",
    "            weighted_confidence = confidence_sum / len(confidences)\n",
    "            # Round to nearest integer since predictions should be integers\n",
    "            final_prediction = round(weighted_avg)\n",
    "        else:\n",
    "            # Fallback to simple average if confidence sum is 0\n",
    "            final_prediction = round(np.mean(predictions))\n",
    "            weighted_confidence = np.mean(confidences) if len(confidences) > 0 else 0.0\n",
    "        \n",
    "        # Find the model with highest confidence for this sentence\n",
    "        max_conf_idx = np.argmax(confidences)\n",
    "        highest_conf_model = models[max_conf_idx]\n",
    "        highest_conf_value = confidences[max_conf_idx]\n",
    "        highest_conf_prediction = predictions[max_conf_idx]\n",
    "        \n",
    "        weighted_results.append({\n",
    "            'Sentence ID': sentence_id,\n",
    "            'Prediction': final_prediction,\n",
    "            'Highest_Conf_Value': highest_conf_value,\n",
    "        })\n",
    "    \n",
    "    # Create final dataframe\n",
    "    result_df = pd.DataFrame(weighted_results)\n",
    "    \n",
    "    # Check if we have any results\n",
    "    if len(result_df) == 0:\n",
    "        print(\"‚ùå ERROR: No valid results generated!\")\n",
    "        return None\n",
    "    \n",
    "    # Sort by Sentence_ID to ensure proper order\n",
    "    result_df = result_df.sort_values('Sentence ID')\n",
    "    \n",
    "    # Convert Sentence_ID to string to match original format if needed\n",
    "    result_df['Sentence ID'] = result_df['Sentence ID'].astype(str)\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_file = \"Average Weighted Predictions_4models.csv\"\n",
    "    result_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"\\n‚úÖ SUCCESS!\")\n",
    "    print(f\"üìÅ File saved as: {output_file}\")\n",
    "    print(f\"üìä Total predictions: {len(result_df)}\")\n",
    "    print(f\"üìã Columns: {result_df.columns.tolist()}\")\n",
    "    print(f\"\\nFirst 10 predictions:\")\n",
    "    print(result_df.head(10))\n",
    "    print(f\"\\nLast 10 predictions:\")\n",
    "    print(result_df.tail(10))\n",
    "    \n",
    "    # Show some statistics\n",
    "    print(f\"\\nPrediction statistics:\")\n",
    "    print(f\"Min prediction: {result_df['Prediction'].min()}\")\n",
    "    print(f\"Max prediction: {result_df['Prediction'].max()}\")\n",
    "    print(f\"Mean prediction: {result_df['Prediction'].mean():.2f}\")\n",
    "    \n",
    "    # Show model distribution\n",
    "    print(f\"\\nModel distribution in data:\")\n",
    "    print(all_predictions['Model'].value_counts())\n",
    "\n",
    "# Run the function\n",
    "result = create_weighted_average_predictions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "599d15f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ File 'Average Weighted Predictions.csv' created successfully!\n",
      "üìä File contains 3420 predictions\n",
      "üìã Columns: ['Sentence_ID', 'Prediction', 'Weighted_Confidence', 'Highest_Conf_Model', 'Highest_Conf_Value', 'Highest_Conf_Prediction', 'Num_Models']\n",
      "\n",
      "üîç First 10 rows:\n",
      "   Sentence_ID  Prediction  Weighted_Confidence Highest_Conf_Model  \\\n",
      "0  10102950001           7             0.678624           MaraBERT   \n",
      "1  10102950002           4             0.600945         AraELECTRA   \n",
      "2  10102950003          11             0.698403         AraELECTRA   \n",
      "3  10102950004           9             0.592355           MaraBERT   \n",
      "4  10102950005           7             0.757594         AraELECTRA   \n",
      "5  10102950006           6             0.561651         AraELECTRA   \n",
      "6  10102950007           6             0.743168         AraELECTRA   \n",
      "7  10102950008           6             0.675883         AraELECTRA   \n",
      "8  10102950009           6             0.592698           MaraBERT   \n",
      "9  10102950010           7             0.745584           MaraBERT   \n",
      "\n",
      "   Highest_Conf_Value  Highest_Conf_Prediction  Num_Models  \n",
      "0            0.992218                        7           3  \n",
      "1            0.787981                        5           3  \n",
      "2            0.976835                       12           3  \n",
      "3            0.743137                       10           3  \n",
      "4            0.980658                        5           3  \n",
      "5            0.689979                        6           3  \n",
      "6            0.943090                        5           3  \n",
      "7            0.858693                        6           3  \n",
      "8            0.723092                        6           3  \n",
      "9            0.917652                        9           3  \n",
      "\n",
      "üîç Last 5 rows:\n",
      "      Sentence_ID  Prediction  Weighted_Confidence Highest_Conf_Model  \\\n",
      "3415  30500290032          14             0.648479           MaraBERT   \n",
      "3416  30500290033          14             0.618396           MaraBERT   \n",
      "3417  30500290034          14             0.595287         AraELECTRA   \n",
      "3418  30500290035          15             0.641174           MaraBERT   \n",
      "3419  30500290036          14             0.661761         AraELECTRA   \n",
      "\n",
      "      Highest_Conf_Value  Highest_Conf_Prediction  Num_Models  \n",
      "3415            0.868815                       14           3  \n",
      "3416            0.748965                       14           3  \n",
      "3417            0.703588                       14           3  \n",
      "3418            0.803523                       15           3  \n",
      "3419            0.803523                       14           3  \n",
      "\n",
      "üìà Prediction Statistics:\n",
      "   Min prediction: 1\n",
      "   Max prediction: 16\n",
      "   Mean prediction: 10.65\n",
      "   Unique predictions: 16\n",
      "\n",
      "üìä Confidence Statistics:\n",
      "   Min weighted confidence: 0.4899\n",
      "   Max weighted confidence: 0.8105\n",
      "   Mean weighted confidence: 0.6541\n",
      "\n",
      "üèÜ Model Performance Analysis:\n",
      "   AraELECTRA: 1747 times most confident (51.1%)\n",
      "   MaraBERT: 1673 times most confident (48.9%)\n",
      "\n",
      "üîç Data Quality Check:\n",
      "   Missing Sentence_ID: 0\n",
      "   Missing Prediction: 0\n",
      "   Missing Weighted_Confidence: 0\n",
      "\n",
      "üìä Confidence Level Examples:\n",
      "Highest confidence predictions:\n",
      "      Sentence_ID  Prediction  Weighted_Confidence Highest_Conf_Model\n",
      "85    10102970032          13             0.810464         AraELECTRA\n",
      "1585  20100250002          11             0.804620           MaraBERT\n",
      "284   10103040012          13             0.801582           MaraBERT\n",
      "\n",
      "Lowest confidence predictions:\n",
      "     Sentence_ID  Prediction  Weighted_Confidence Highest_Conf_Model\n",
      "321  10103050035           1             0.489857           MaraBERT\n",
      "295  10103050009           7             0.517436         AraELECTRA\n",
      "115  10102990001           7             0.521449           MaraBERT\n"
     ]
    }
   ],
   "source": [
    "# Let's verify the enhanced output file was created correctly\n",
    "import os\n",
    "\n",
    "# Check if the file exists\n",
    "output_file = \"Average Weighted Predictions.csv\"\n",
    "if os.path.exists(output_file):\n",
    "    print(f\"‚úÖ File '{output_file}' created successfully!\")\n",
    "    \n",
    "    # Read and display the file info\n",
    "    verify_df = pd.read_csv(output_file)\n",
    "    print(f\"üìä File contains {len(verify_df)} predictions\")\n",
    "    print(f\"üìã Columns: {verify_df.columns.tolist()}\")\n",
    "    \n",
    "    # Show first and last few rows\n",
    "    print(f\"\\nüîç First 10 rows:\")\n",
    "    print(verify_df.head(10))\n",
    "    \n",
    "    print(f\"\\nüîç Last 5 rows:\")\n",
    "    print(verify_df.tail(5))\n",
    "    \n",
    "    # Show statistics\n",
    "    print(f\"\\nüìà Prediction Statistics:\")\n",
    "    print(f\"   Min prediction: {verify_df['Prediction'].min()}\")\n",
    "    print(f\"   Max prediction: {verify_df['Prediction'].max()}\")\n",
    "    print(f\"   Mean prediction: {verify_df['Prediction'].mean():.2f}\")\n",
    "    print(f\"   Unique predictions: {verify_df['Prediction'].nunique()}\")\n",
    "    \n",
    "    print(f\"\\nüìä Confidence Statistics:\")\n",
    "    print(f\"   Min weighted confidence: {verify_df['Weighted_Confidence'].min():.4f}\")\n",
    "    print(f\"   Max weighted confidence: {verify_df['Weighted_Confidence'].max():.4f}\")\n",
    "    print(f\"   Mean weighted confidence: {verify_df['Weighted_Confidence'].mean():.4f}\")\n",
    "    \n",
    "    print(f\"\\nüèÜ Model Performance Analysis:\")\n",
    "    model_counts = verify_df['Highest_Conf_Model'].value_counts()\n",
    "    for model, count in model_counts.items():\n",
    "        percentage = (count / len(verify_df)) * 100\n",
    "        print(f\"   {model}: {count} times most confident ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Check for any missing values\n",
    "    print(f\"\\nüîç Data Quality Check:\")\n",
    "    print(f\"   Missing Sentence_ID: {verify_df['Sentence_ID'].isna().sum()}\")\n",
    "    print(f\"   Missing Prediction: {verify_df['Prediction'].isna().sum()}\")\n",
    "    print(f\"   Missing Weighted_Confidence: {verify_df['Weighted_Confidence'].isna().sum()}\")\n",
    "    \n",
    "    # Show some examples of different confidence levels\n",
    "    print(f\"\\nüìä Confidence Level Examples:\")\n",
    "    high_conf = verify_df.nlargest(3, 'Weighted_Confidence')[['Sentence_ID', 'Prediction', 'Weighted_Confidence', 'Highest_Conf_Model']]\n",
    "    print(\"Highest confidence predictions:\")\n",
    "    print(high_conf)\n",
    "    \n",
    "    low_conf = verify_df.nsmallest(3, 'Weighted_Confidence')[['Sentence_ID', 'Prediction', 'Weighted_Confidence', 'Highest_Conf_Model']]\n",
    "    print(\"\\nLowest confidence predictions:\")\n",
    "    print(low_conf)\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ùå File '{output_file}' was not created!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
